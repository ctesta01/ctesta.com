[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Christian Testa",
    "section": "",
    "text": "GitHub\n  \n  \n    \n     Mastodon\n  \n  \n    \n     Google Scholar\n  \n\n  \n  \n\n\nHello! I am a first year PhD student in the Department of Biostatistics at the Harvard T.H. Chan School of Public Health. My research interest areas include causal inference, infectious diseases, and spatial statistics.\nRecently I worked (2020-2023) as a statistical data analyst with Nancy Krieger and Jarvis Chen in the Department of Social and Behavioral Sciences at the Harvard T.H. Chan School of Public Health on projects including:\n\nThe Public Health Disparities Geocoding Project 2.0\nTwo NIH R01 grant funded projects:\n\nDNA methylation & adversity: pathways from exposures to health inequities\nAdvancing novel methods to measure and analyze multiple types of discrimination for population health research\n\nA COVID-19 Paper Series\nPrior, I worked (2017-2020) in the Department of Global Health and Population at Harvard T.H. Chan School of Public Health with Joshua Soloman (now at Stanford) and Nicolas Menzies in the Prevention Policy Modeling Lab as a data analyst and programmer on several CDC grant funded projects.\nThose projects included:\nI received my Bachelors of Science in Mathematics from Tufts University in 2017."
  },
  {
    "objectID": "blog.html",
    "href": "blog.html",
    "title": "Blog Content",
    "section": "",
    "text": "Brief History of Probability Notes\n\n\n\n\n\n\nnotes\n\n\nprobability\n\n\nstatistics\n\n\n\n\n\n\n\n\n\nSep 3, 2024\n\n\nChristian Testa\n\n\n\n\n\n\n\n\n\n\n\n\nBhramar Mukherjee’s Marvin Zelen Award Talk\n\n\n\n\n\n\ntalks\n\n\nstatistics\n\n\n\n\n\n\n\n\n\nMay 12, 2024\n\n\nChristian Testa\n\n\n\n\n\n\n\n\n\n\n\n\nOur Trip to Seattle\n\n\n\n\n\n\nphotography\n\n\ntravel\n\n\n\n\n\n\n\n\n\nJul 10, 2023\n\n\nChristian Testa\n\n\n\n\n\n\n\n\n\n\n\n\nScale (Zoom) Dependent Maps with Leaflet in R\n\n\n\n\n\n\ngeography\n\n\nmapping\n\n\nR\n\n\nprogramming\n\n\ndata-science\n\n\n\n\n\n\n\n\n\nJun 10, 2023\n\n\nChristian Testa\n\n\n\n\n\n\n\n\n\n\n\n\nThe first offering of ID529 Data Management and Analytic Workflows in R at Harvard\n\n\n\n\n\n\nteaching\n\n\n\n\n\n\n\n\n\nFeb 13, 2023\n\n\nChristian Testa\n\n\n\n\n\n\n\n\n\n\n\n\nRelationship of political ideology of US federal and state elected officials and key COVID pandemic outcomes\n\n\n\n\n\n\npublications\n\n\n\n\n\n\n\n\n\nNov 1, 2022\n\n\nChristian Testa\n\n\n\n\n\n\n\n\n\n\n\n\nThe Public Health Disparities Geocoding Project 2.0\n\n\n\n\n\n\nresearch\n\n\nteaching\n\n\n\n\n\n\n\n\n\nOct 1, 2022\n\n\nChristian Testa\n\n\n\n\n\n\n\n\n\n\n\n\n2021 in Review\n\n\n\n\n\n\nyearly-review\n\n\nphotography\n\n\npublications\n\n\n\n\n\n\n\n\n\nDec 26, 2021\n\n\n\n\n\n\n\n\n\n\n\n\nBoston Night Skyline\n\n\n\n\n\n\nphotography\n\n\n\n\n\n\n\n\n\nJun 1, 2021\n\n\nChristian Testa\n\n\n\n\n\n\n\n\n\n\n\n\nSimulation, Error, and Modeling the Physical World\n\n\n\n\n\n\nsimulation\n\n\nmodeling\n\n\nphysics\n\n\n\n\n\n\n\n\n\nMar 20, 2021\n\n\nChristian Testa\n\n\n\n\n\n\n\n\n\n\n\n\nIntro to Gaussian Processes\n\n\n\n\n\n\nmachine-learning\n\n\nstatistics\n\n\n\n\n\n\n\n\n\nJan 16, 2021\n\n\nChristian Testa\n\n\n\n\n\n\n\n\n\n\n\n\nNational Zoo, 2018\n\n\n\n\n\n\nphotography\n\n\ntravel\n\n\n\n\n\n\n\n\n\nNov 23, 2018\n\n\nChristian Testa\n\n\n\n\n\n\n\n\n\n\n\n\nHOPE 2020\n\n\n\n\n\n\ntechnology\n\n\nconferences\n\n\n\n\n\n\n\n\n\nNov 23, 2018\n\n\nChristian Testa\n\n\n\n\n\n\n\n\n\n\n\n\nResources for R Programmers\n\n\n\n\n\n\nR\n\n\nprogramming\n\n\n\n\n\n\n\n\n\nMay 24, 2018\n\n\nChristian Testa\n\n\n\n\n\n\n\n\n\n\n\n\nIntroduction to the Theory of Elliptic Curves\n\n\n\n\n\n\nmathematics\n\n\n\n\n\n\n\n\n\nMar 18, 2017\n\n\nChristian Testa\n\n\n\n\n\n\n\n\n\n\n\n\nQualtricsTools : Automated Survey Processing\n\n\n\n\n\n\nsurveys\n\n\nR\n\n\nshiny\n\n\n\n\n\n\n\n\n\nMar 17, 2017\n\n\nChristian Testa\n\n\n\n\n\n\n\n\n\n\n\n\nWashington State Photography\n\n\n\n\n\n\nphotography\n\n\ntravel\n\n\n\nI took some photos in Olympic National Park and around Seattle\n\n\n\n\n\nAug 31, 2016\n\n\nChristian Testa\n\n\n\n\n\n\n\n\n\n\n\n\nColorado State Photography\n\n\n\n\n\n\nphotography\n\n\ntravel\n\n\n\nI took some photos in Rocky Mountain National Park and around Denver\n\n\n\n\n\nAug 31, 2016\n\n\nChristian Testa\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "publications.html",
    "href": "publications.html",
    "title": "Publications",
    "section": "",
    "text": "Forthcoming\n\n Understanding Complex Patterns in Social, Geographic, and Economic Inequities in COVID-19 Mortality at the County Level in the US Using Generalized Additive Models \n\n Testa C. Preprint on arXiv.\n\n The evolving roles of US political partisanship and social vulnerability in the COVID-19 pandemic from February 2020–February 2021 \n\nKaashoek J, Testa C, Chen JT, Stolerman L, Krieger N, Hanage WP, Santillana M. PLOS Global Public Health.\n\n Use of incorrect and correct methods to account for age in studies on epigenetic accelerated aging: implications and recommendations for best practices \n\nKrieger N, Chen JT, Testa C, Chen JT, Diez Roux AV, Tilling K, Watkins SH, Simpkin AJ, Suderman MJ, Davey Smith G, De Vivo I, Waterman PD, Relton CL. American Journal of Epidemiology.\n\nTabby2: A User-Friendly Web Tool for Forecasting State-Level TB Outcomes in the United States\n\nSwartwood NA, Testa C Cohen T, Marks SM, Hill AN, Beeler-Assay G, Cochran J, Cranston K, Randall LM, Tibbs A, Horsburgh CR, Salomon JA, Menzies NA. BMC Medicine.\n\nThe contribution of latent TB treatment to TB prevention in the United States: results of a transmission dynamic model\n\nSwartwood NA, Testa C Cohen T, Marks SM, Hill AN, Beeler-Assay G, Cochran J, Cranston K, Randall LM, Tibbs A, Horsburgh CR, Salomon JA, Menzies NA.\n\n\n2022\n\n Relationship of political ideology of US federal and state elected officials and key COVID pandemic outcomes following vaccine rollout to adults: April 2021–March 2022 \n\nKrieger N, Testa C, Chen JT, Hanage WP, McGregor AJ. The Lancet Regional Health — Americas.\n\n Estimated costs and quality-adjusted life-years lost due to N. gonorrhoeae infections acquired in 2015 in the United States: A modelling study of overall burden and disparities by age, race/ethnicity, and other factors \n\nLi Y, Rönn MM, Tuite AR, Chesson HW, Gift TL, Trikalinos TA, Testa C, Bellerose M, Hsu K, Berruti AA, Malyuta Y, Menzies NA, Salomon JA. The Lancet Regional Health — Americas.\n\n The Public Health Disparities Geocoding Project 2.0 Training Manual \n\nTesta C, Chen JT, Hall E, Javadi D, Morgan J, Rushovich T, Saha S, Waterman PD, Krieger N.\n\n Epigenetic clocks and research implications of the lack of data on whom they have been developed: a review of reported and missing sociodemographic characteristics \n\nWatkins SH, Testa C, Chen JT, De Vivo I, Simpkin AJ, Tilling K, Diez Roux AV, Davey Smith G, Waterman PD, Suderman M, Relton CL, Krieger N. OSF Preprints.\n\n The impact of low input DNA on the reliability of DNA methylation as measured by the Illumina Infinium MethylationEPIC BeadChip \n\nWatkins SH, Ho K, Testa C, Falk L, Soul P, Nguyen LV, FitzGibbon S, Slack C, Chen JT, Davey Smith G, De Vivo I, Simpkin AJ, Tilling K, Waterman PD, Krieger N, Suderman M, Relton C. Epigenetics.\n\n Using Implicit Measures of Discrimination: White, Black, and Hispanic Participants Respond Differently to Group-Specific Racial/Ethnic Categories vs. the General Category “People of Color” in the USA \n\nMarini M, Waterman PD, Breedlove ER, Chen JT, Testa C, Pardee DJ, LeBlanc M, Reisner SL, Oendari A, Krieger N. Journal of Racial and Ethnic Health Disparities.\n\n Breast Cancer Incidence, Hormone Receptor Status, Historical Redlining, and Current Neighborhood Characteristics in Massachusetts, 2005-2015 \n\nWright E, Waterman PD, Testa C, Chen JT, Krieger N. JNCI Cancer Spectrum.\n\n\n2021\n\n Modeling the Cost-Effectiveness of Express Multi-Site Gonorrhea Screening among Men Who Have Sex with Men in the United States \n\nEarnest R, Rönn MM, Bellerose M, Menon-Johansson AS, Berruti AA, Chesson HW, Gift TL, Hsu KK, Testa C, Zhu L, Malyuta Y, Menzies NA, Salomon JA. Sexually Transmitted Diseases.\n\n Missing again: US racial and ethnic data for COVID-19 vaccination \n\nKrieger N, Waterman PD, Chen JT, Testa C, Hanage WP. The Lancet.\n\n Regional heterogeneity in COVID-19 risk in the United States during the time of Delta (July 1 – September 15, 2021): The US south suffers the highest case and death rates and greatest inequities \n\nKrieger N, Chen JT, Testa C, Waterman PD, Hanage WP. HCPDS Working Paper Series.\n\n COVID-19: US federal accountability for entry, spread, and inequities—lessons for the future \n\nHanage WP, Testa C, Chen JT, Davis L, Pechter E, Seminario P, Santillana M, Krieger N. European Journal of Epidemiology.\n\n US racial and ethnic data for COVID-19 cases: still missing in action \n\nKrieger N, Testa C, Hanage WP, Chen JT. The Lancet.\n\n Time Since Infection and Risks of Future Disease for Individuals with Mycobacterium tuberculosis Infection in the United States \n\nMenzies NA, Swartwood N, Testa C, Malyuta Y, Hill AN, Marks SM, Cohen T, Salmon JA. Epidemiology.\n\n Picturing prevention: Visualizing how vaccination profoundly protects your loved ones, you, and your community from hospitalization and death due to Covid- 19 using real-life data from 12 US states (January – July 2021) \n\nChen JT, Testa C, Hanage WP, Krieger N. HCPDS Working Paper Series.\n\n COVID-19 and exacerbation of screening mammography inequities. \n\nWang GX, Chen JT, Lamb L, Testa C, Waterman PD, Lehman CD, Krieger N. Journal of Clinical Oncology, Meeting Abstract.\n\n Intersectional inequities in COVID-19 mortality by race/ethnicity and education in the United States, January 1, 2020–January 31, 2021 \n\nChen JT, Testa C, Waterman PD, Krieger N. HCPDS Working Paper Series.\n\n The target/perpetrator brief-implicit association test (B-IAT): an implicit instrument for efficiently measuring discrimination based on race/ethnicity, sex, gender identity, sexual orientation, weight, and age \n\nMaddalena M, Waterman PD, Breedlove E, Chen JT, Testa C, Reisner SL, Pardee DJ, Mayer KHand Krieger N. BMC Public Health.\n\n\n2020\n\n Exploring How Epidemic Context Influences Syphilis Screening Impact: A Mathematical Modeling Study\n\nTuite AR†, Testa C†, Rönn MM, Bellerose M, Gift T, Fridge J, Molotnikov L, Desmarais C, Berruti Andrés, Menzies N, Malyuta Y, Hsu K, Salomon JA. Sexually Transmitted Diseases. †Contributed equally.\n\n Impact of effective global tuberculosis control on health and economic outcomes in the United States \n\nMenzies NA, Bellerose M, Testa C, Swartwood N, Malyuta Y, Cohen T, Marks SM, Hill AN, Date AA, Maloney SA, Bowden SE, Grills AW, Salomon JA. American Journal of Respiratory and Critical Care Medicine.\n\n The Potential Population-Level Impact of Different Gonorrhea Screening Strategies in Baltimore and San Francisco: An Exploratory Mathematical Modeling Analysis \n\nRönn MM†, Testa C†, Tuite AR, Chesson HW, Gift TL, Schumacher C, Williford SL, Zhu L, Bellerose M, Earnest R, Malyuta Y, Hsu KK, Salomon JA, Menzies NA. Sexually Transmitted Diseases. †Contributed equally.\n\n Population-level Benefits of Extragenital Gonorrhea Screening Among Men Who Have Sex With Men: An Exploratory Modeling Analysis \n\nEarnest R, Rönn MM, Bellerose M, Gift T, Berruti AA, Hsu KK, Testa C, Zhu L, Malyuta Y, Menzies NA, Salomon JA. Sexually Transmitted Diseases.\n\n\nPress\n\n\n Attack America’s overlapping miseries: Why going big on relief is an economic, public health and moral imperative \n\nThis opinion piece we (Nancy Krieger, Christian Testa, Pamela Waterman and Jarvis Chen) published in the New York Daily News presents a data driven perspective on the concurrent tragedies of economic insecurity and COVID-19. We argue that federal relief addressing both of these needs is urgently necessary.\n\n Workers Tried To Blow The Whistle On COVID Hazards. Then People Died. \n\nThis article by Dave Jamieson in the HuffPost featured our work which showed that COVID-19 cases and deaths were consistently preceded by complaints filed with the Occupational Safety and Health Administration (OSHA).\n\n\n\n\nWorking Papers\n\n\n\n2021\n\n Intersectional inequities in COVID-19 mortality by race/ethnicity and education in the United States, January 1, 2020–January 31, 2021 \n\nChen JT, Testa C, Waterman PD, Krieger N.\n\n Go big on relief! – repairing the commingled miseries of COVID-19 and US housing and food insecurity \n\nKrieger N, Testa C, Waterman PD, Chen JT.\n\n Plague of US missing COVID-19 data for race/ethnicity: Debacle continues with vaccination data \n\nKrieger N, Waterman PD, Chen JT, Testa C, Santillana M, Hanage WP. HCPDS Working Paper Series.\n\n Political lean: A crucial variable for monitoring COVID-19 in the United States \n\nKrieger N, Chen JT, Testa C, Waterman PD, Hangae WP. HCPDS Working Paper Series.\n\n\n2020\n\n Warning against using static US county-level community data to guide equity in COVID-19 vaccine distribution: Temporal and spatial correlations of community characteristics with COVID-19 cases and deaths vary enormously and are increasingly uninformative \n\nKrieger N, Testa C, Chen JT, Waterman PD, Hanage WP.\n\n The changing political geographies of COVID-19 in the US \n\nKrieger N, Chen JT, Testa C, Hanage WP.\n\n COVID-19: US Federal accountability for entry, spread, and inequities \n\nHanage WP, Testa C, Chen JT, Davis L, Pechter E, Santillana M, Krieger N.\n\n US racial/ethnic data for COVID-19 cases: Still missing-in-action \n\nKrieger N, Testa C, Chen JT.\n\n Visualizing the lagged connection between COVID-19 cases and deaths in the United States: An animation using per capita state-level data (January 22, 2020 – July 8, 2020) \n\nTesta C, Krieger N, Chen JT, Hanage WP.\n\n Defining high-value information for COVID-19 decision-making \n\nBilinski A, Birger R, Burn S, Chitwood M, Clarke-Deelder E, Copple T, Eaton J, Ehrlich H, Erlendsdottir M, Eshghi S, Farid M, Fitzpatrick M, Giardina J, Gonsalves G, Hsieh YL, Iloglu S, Kao Y, MacKay E, Menzies NA, Mulaney B, Paltiel D, Perniciaro S, Phillips M, Rich K, Salomon JA, Sherak R, Shioda K, Swartwood N, Testa C, Thornhill T, White E, Williamson A, York A, Zhu J, Zhu L. medRxiv. Authors in alphabetical order.\n\n\n\n\nConference Posters\n\n\n\n2019\n\n A User Friendly Web Tool for Exploring Future State-Level TB Outcomes for User-Specified Scenarios \n\nTesta C, Swartwood NA, Cohen T, Marks SM, Hill AN, Cochran J, Cranston K, Randall LM, Tibbs A, Salomon JA, Menzies NA. National TB Controllers Association Conference. Awarded 2nd place in the poster competition.\n\n Modeling Interventions for TB in the United States: a flexible framework for modelling TB epidemiology and policy effects \n\nSwartwood NA, Testa C, Cohen T, Marks SM, Hill AN, Cochran J, Cranston K, Randall LM, Tibbs A, Salomon JA, Menzies NA. National TB Controllers Association Conference.\n\nPotential benefits of screening for gonorrhea in two urban centers: exploratory mathematical modeling analysis\n\nRönn MM†, Testa C†, Tuite AR, Gift TL, Chesson HW, Schumacher C, Humes E, Menzies NA, Earnest R, Bellerose M, Malyuta Y, Hsu K, Salomon JA. STD Prevention Conference. †Contributed equally."
  },
  {
    "objectID": "posts/2023-07-10-seattle.html",
    "href": "posts/2023-07-10-seattle.html",
    "title": "Our Trip to Seattle",
    "section": "",
    "text": "Seattle was so much fun! I don’t know how on Earth we did so much in just two days, but we did.\nAs soon as we got off the plane, picked up our rental car and checked into our hotel, we were super famished so we set out and found some amazing Mexican food pretty close to the airport at El Cabrito.\n\n\n\n  \n\n\n  \n\n\n\n\n  \n\n\n  \n\n\n\n\n  \n\n\n\nNext up was the Chihuly Garden and Glass museum! The glass was the focal point, but the drinks in the garden were pretty great too: the cold brew with pistachio foam, and frozen banana & kalamansi mai tais were pretty unforgettable.\n\n\n\n  \n\n\n  \n\n\n\n\n  \n\n\n  \n\n\n\n\n  \n\n\n  \n\n\n\n\n  \n\n\n  \n\n\n\n\n  \n\n\n  \n\n\n\n\n  \n\n\n  \n\n\n\n\n  \n\n\n  \n\n\n\n\n  \n\n\n  \n\n\n\n\n  \n\n\n  \n\n\n\n\n  \n\n\n  \n\n\n\n\n  \n\n\n  \n\n\n\n\n  \n\n\n\nAfter we went to the Chihuly Garden and Glass exhibits we went to the Space Needle. It was neat seeing all the history about its construction as we queued for the elevator, and the attendants’ 41 second speeches that were perfectly timed to the elevator ride were quite impressive. Jane is working on her fear of glass bottom buildings ☺️\n\n\n\n  \n\n\n  \n\n\n\n\n  \n\n\n\nFor dinner, we headed over to the Capitol Hill neighborhood and met up with some friends at Oddfellows Cafe + Bar and then went around the corner for ice cream at Molly Moon’s Homemade Ice Cream.\n\n\n\n  \n\n\n  \n\n\n\n\n  \n\n\n\nDay 2\n\nTo start off our second day, we had to go to Temple Pastry since I’d heard it had some of the very best French pastries. I loved the vibe and I picked up that little travel coffee mug with the nice design on it as a souvenir. Outside we met two cute Shibas that I think were minor gods of mischief.\n\n\n\n  \n\n\n  \n\n\n\n\n  \n\n\n  \n\n\n\n\n  \n\n\n  \n\n\n\n\n  \n\n\n  \n\n\n\n\n  \n\n\n  \n\n\n\n\n  \n\n\n\nAfter our breakfast at Temple Pastry and getting lunch at Din Tai Fung, it was off to our friend’s wedding: our purpose for being in Seattle! After walking in we immediately pounced on their dogs to say hi to them; their names are Penguin (nickname: Gwen) and Nala.\nThe wedding was beautiful! It was outdoors by a nice little stream on a farm house about 30 minutes from where we were staying. The bride’s mother made these amazing glass blown sunflowers that were the table decorations, of which there must have been over a 100. We were instructed to take those home, so those will be another nice keepsake of ours from this trip.\n\n\n\n  \n\n\n  \n\n\n\n\n  \n\n\n  \n\n\n\n\n  \n\n\n  \n\n\n\n\n  \n\n\n  \n\n\n\n\n  \n\n\n  \n\n\n\n\n  \n\n\n\nDay 3\n\nFor breakfast on the third day, we tried going one place but then saw it had over an hour wait, so we got back in the car and went to Cheeky Cafe. We did have to wait a while for our food, but once it got to us it was to-die-for. Jane noticed that there was spicy kimchi mac & cheese on the menu and obviously we were going to get that. It was incredible! Very creamy, right level of spicy, umami, delicious. And the wasabi dressing side-salad was pretty good too, actually. I got their french toast and Jane got their “Cheeky french toast” which was stuffed with bananas. Both were great!\n\n\n\n  \n\n\n  \n\n\n\n\n  \n\n\n  \n\n\n\n\n  \n\n\n  \n\n\n\nNext we went to the Univeristy of Washington Arboretum and toured the Japanese Garden there. It was perfect weather for it, in the low 70s with a cool breeze. We spent a lot of time just lounging in the gazebos. For the legal nerds: “How do tortoises settle their disputes? Tort law!”\n\n\n\n  \n\n\n  \n\n\n\n\n  \n\n\n  \n\n\n\n\n  \n\n\n  \n\n\n\n\n  \n\n\n  \n\n\n\n\n  \n\n\n  \n\n\n\n\n  \n\n\n  \n\n\n\n\n  \n\n\n  \n\n\n\nWe wanted to get inside for a while to cool off and relax, so we went over to Ada’s Technical Books and Cafe and just read for a bit. Outside of Ada’s we spotted this really neat mural made out of brightly colored floppy disks. What a blast from the past! After that we went over to Carmelo’s Tacos and had a few more great tacos.\n\n\n\n  \n\n\n  \n\n\n\n\n  \n\n\n  \n\n\n\n\n  \n\n\n  \n\n\n\n\n  \n\n\n  \n\n\n\n\n  \n\n\n\nYou might be wondering “what was Hodu doing during all of this?” Rest assured, he was living his best life, re-enacting Totoro and napping off the hot days in Boston at a friend’s place.\n\n\n\nFinally, and I still don’t know how we survived doing this, but we took a red-eye back (9:30pm to 5:45am) so I could make my Monday morning 9am meeting."
  },
  {
    "objectID": "posts/2016-08-31-Washington-State-Photography.html",
    "href": "posts/2016-08-31-Washington-State-Photography.html",
    "title": "Washington State Photography",
    "section": "",
    "text": "In 2016 I visited Washington state, including Seattle, Olympic National Park, and Olympic National Forest. The mist and fog hanging over the roads through the mountains and forest on the way to Olympic National Park made the experience calm and tranquil. The beach was beautiful, bright blue with tide pools and anemone. The stacks of hard rock carved away by the tide coming in and out create a beautiful ocean and beach landscape, with a consistently interesting horizon to fall in love with. Seattle had a very fun culture to appreciate, from plenty of art museums, graffiti, monuments, and history. Absolutely check out the beautiful art at the Chihuly glass museum if you get the chance. It is phenomenal and impressive. I would love to visit Washington state again, and the first item on my agenda would be getting back to Olympic National Park."
  },
  {
    "objectID": "posts/2016-08-31-Colorado-State-Photography.html",
    "href": "posts/2016-08-31-Colorado-State-Photography.html",
    "title": "Colorado State Photography",
    "section": "",
    "text": "I went to Colorado in the summer of 2016 and found some heart-moving and serene photography opportunities. I spent time in Denver, Boulder, and, of course, the Rocky Mountain National Park. I struggle to imagine a more picturesque photography experience than that with the brazen elk right next to the road and the incredible and towering mountain ranges spanning the park. The sense of peace that I could derive from spending time in the park is a memory that will always motivate my desire to spend more time in nature. I truly enjoyed my time in Colorado, and I recommend that anybody with an interest in the outdoors find the time to enjoy the beautiful scenery there."
  },
  {
    "objectID": "posts/2021-01-16-Gaussian-Processes.html",
    "href": "posts/2021-01-16-Gaussian-Processes.html",
    "title": "Intro to Gaussian Processes",
    "section": "",
    "text": "In this article I’m going to try to provide some intuition around how multivariate Gaussian distributions and Gaussian process models can be useful for modeling smooth functions.\n\n\n\n\nA helpful definition\n\n\nA random variable (X) in (d) dimensions is multivariate normally distributed e.g. (X N_d(, )) if and only if (_i _i X_i N(', ')) for any choice of ({ _i }) and (i) taken across any subset of ({1, …, d}) for some (') and ('). In other words, the sum or linear combination of any subset of a multivariate normal distribution’s components is a normal distribution.\n\n\n\n\nUnderstanding the Role of the Covariance Matrix\n\n\nIt’s useful to consider the extremal situations first.\n\n\nHere’s a draw from a multivariate normal distribution where the mean is 0 and the covariance matrix is all 1s:\n\n\n\n\n\nThe covariance matrix being full of ones forces all elements of the vector to be exactly the same.\n\n\nThe other extreme is when the covariance matrix is 1 on the diagonal entries and 0 everywhere else. Here’s a draw from that distribution, again with mean 0:\n\n\n\n\n\nThis results in a very noisy vector which is still roughly centered at 0.\n\n\nAnother easy covariance matrix to specify is where the off-diagonal elements are all some fixed number, say .999:\n\n\n\n\n\nThis results in a noisy vector, but where all the entries are correlated with each other, resulting in reduced deviation within the components of the draw.\n\n\n\n\nUsing Gaussian Kernels\n\n\nNow that we understand how the multivariate normal distribution acts given some examples of covariance matrices, we can think about more practical situations such as when the covariance matrix is defined based off a kernel function like the Gaussian kernel.\n\n\nThe Gaussian kernel is defined as (K(x_1, x_2) = (-(x_1-x_2)^2)) for some choice of smoothing parameter ().\n\n\nGiven (X = [0, 0.1, 0.2, …, 10]) we can define our covariance matrix as ([K(X_i,X_j)]_{{i,j}}). Essentially this results in a covariance matrix where neighboring components (and nearby components) are expected to be highly correlated while more distant components are expected to have less correlation.\n\n\nFirst, here’s an example with ():\n\n\n\n\n\nIf we reduce () to .1 we get more wiggles:\n\n\n\n\n\n\n\nFunction Approximation using MVNs and the Gaussian Kernel\n\n\nIt’s useful to note that throughout the Bayesian Statistics literature one can find frequent references to “Gaussian Processes” which are defined as having a prior distribution given by a multivariate normal distribution. Gaussian Process models have made quite the splash in areas of machine learning and statistics as a flexible means of modeling smooth surfaces. Sometimes Gaussian Process Models also go by the name of “kriging” which commonly comes up in geospatial statistics.\n\n\nTo create an example scenario in which we can apply some Gaussian Process modeling, let’s define a wiggly function from which we will take some sample observations. Then we will fit the data using a Gaussian Process model and see how the model compares to the true function. We won’t take model assessment too seriously here, but we will qualitatively compare the Gaussian Process model’s performance to other common techniques like cubic splines and locally weighted smoothing (loess).\n\nh_func <- function(x) { cos(x^2) + x }\nn <- 25\nX <- runif(n,0,4)\nh_vals <- h_func(X)\nh_mean <- mean(h_vals)\nh_vals <- h_vals - h_mean\n\nNote that we’re centering the data so that it’s compatible with our later assumption that (= 0) for our Gaussian Process model.\n\n\n\n\n\nNow we specify the Gaussian Process model below using Stan.\n\ndata {\n  int<lower=1> N1;\n  real x1[N1];\n  vector[N1] y1;\n  int<lower=1> N2;\n  real x2[N2];\n}\ntransformed data {\n  real delta = 1e-9;\n  int<lower=1> N = N1 + N2;\n  real x[N];\n  for (n1 in 1:N1) x[n1] = x1[n1];\n  for (n2 in 1:N2) x[N1 + n2] = x2[n2];\n}\nparameters {\n  real<lower=0> rho;\n  real<lower=0> alpha;\n  real<lower=0> sigma;\n  vector[N] eta;\n}\ntransformed parameters {\n  vector[N] f;\n  {\n    matrix[N, N] L_K;\n    matrix[N, N] K = cov_exp_quad(x, alpha, rho);\n\n    // diagonal elements\n    for (n in 1:N)\n      K[n, n] = K[n, n] + delta;\n\n    L_K = cholesky_decompose(K);\n    f = L_K * eta;\n  }\n}\nmodel {\n  rho ~ inv_gamma(5, 5);\n  alpha ~ std_normal();\n  sigma ~ std_normal();\n  eta ~ std_normal();\n\n  y1 ~ normal(f[1:N1], sigma);\n}\ngenerated quantities {\n  vector[N2] y2;\n  for (n2 in 1:N2)\n    y2[n2] = f[N1 + n2];\n}\n\n\n\n\nWe can see the model does fairly well in the area [0,3.75] range, but the model is definitely not great for extrapolating when the function does not decay to 0 outside the observed area.\n\n\nWe can compare this to how cubic splines perform:\n\n\n\n\n\nThe cubic spline regression seems to underperform in some of the less observed areas within the [0,3.75] range compared to the Gaussian Process model.\n\n\nAnd then with loess:\n\n\n\n\n\nLoess seems to apply a lot more smoothing and less interpolation compared to the cubic spline and Gaussian Process model approaches. It would be interesting to see if this property means that loess performs better on more noisy data.\n\n\n\n\nNext Steps\n\n\nAll in all, I think the details provided here provide a helpful intuition about the basic behavior of multivariate normal distributions and how they can be used to define Gaussian Process models in 1 dimension.\n\n\nI think further intuition about how they perform when faced with data that includes noise as well as higher dimensions would be valuable and enlightening.\n\n\n\n\n\n\n\n\n\nReferences\n\n\nSurrogates, Gaussian process modeling, design and optimization for the applied sciences, Chapter 5. Robert B. Gramacy. https://bookdown.org/rbg/surrogates/chap5.html\n\n\nStan User’s Guide, Section 10.3 Fitting a Gaussian Process. https://mc-stan.org/docs/2_19/stan-users-guide/fit-gp-section.html"
  },
  {
    "objectID": "posts/2021-03-20-AM227.html",
    "href": "posts/2021-03-20-AM227.html",
    "title": "Simulation, Error, and Modeling the Physical World",
    "section": "",
    "text": "A few years ago I took a course from Sauro Succi called Computational Methods for the Physical Sciences that surveyed topics such as computational methods for solving partial differential equations, methods for simulating physical systems where processes span different scales of magnitude such as turbulence or fracturing materials, and statistical physics.\nArguably the most interesting feature of the course was the Lattice-Boltzmann method for simulating fluid dynamics that has particular advantages in its efficiency and amenability to parallelization.\nThroughout this course I created a handful of visualizations that, looking back on, seem worth sharing. The first of which, depicted above, shows a normally distributed mass shifting across periodic boundaries on the left and right hand sides as it slowly diffuses and spreads out. There’s nothing deep about this, I just thought the visualization looks nice.\n\n\n\nA rectangular distribution of mass is shown in multiple iterations where the edges start to rapidly oscillate due to Gibbs phenomenon in a way that doesn’t reflect what would really happen in reality (the rectangle would just move to the side).\n\n\nOne of the concepts introduced in this course was Gibbs phenomenon which is what happens in a variety of contexts, the most popular of which being when one either attempts to approximate a square distribution through Fourier decomposition, or when one attempts to propogate a square distribution of mass over a discretized model of space. The result is that when the movement does not exactly line up with the discretization of space, the approximation of how much mass is at each discrete point in space can go quite haywire.\n\n\n\nA normal distribution is shown “puffing up” after each iteration, eventually appearing as though it has puffed up against an upper limit past which it cannot puff anymore\n\n\nThis is a visualization of some material which can be thought of as reacting with itself in a way that produces more of itself (not realistic, I know) up to the observed carrying capacity. Again, nothing profound, just an aesthetically pleasing visualization.\nFor my final project in this course, I worked on a spatial model of infectious disease transmission with stochasticity and reinfection. I think infectious disease modeling is a fascinating subject and I’m suspicious it’s worth thinking through the intricacies of how stochasticity can affect disease dynamics in ways that deterministic equations might not reveal."
  },
  {
    "objectID": "posts/2018-11-23-DC-Zoo.html",
    "href": "posts/2018-11-23-DC-Zoo.html",
    "title": "National Zoo, 2018",
    "section": "",
    "text": "These are just a handful of the shots I thought turned out best from a trip I took down to Washington DC in 2018. Besides visiting the National Zoo, I danced at the DC DanceSport Inferno (DCDI) hosted at the University of Maryland while I was in town and it was great to catch up with a friend that’s been going to law school at Georgetown. We also managed to sneak in a little trip to the Hirshhorn Modern Art Museum.\nI just want to make one clarifying point that a lot of people seem to overlook. While red pandas’ fur markings are incredibly cute, they’re also quite ferocious little beasts and they have pretty menacing claws.\nI have been truly captivated with the alligator snapping turtle depicted below for a while now. The male alligator snapping turtles can weigh up to 200 pounds. Moreover, like tortoises, turtles like these can live exceptionally long lifetimes, possibly over 150 years. Read more about turtle longevity in this 1987 BioScience article, Why Do Turtles Live So Long?"
  },
  {
    "objectID": "posts/2022-11-01-political-ideology-and-covid.html",
    "href": "posts/2022-11-01-political-ideology-and-covid.html",
    "title": "Relationship of political ideology of US federal and state elected officials and key COVID pandemic outcomes",
    "section": "",
    "text": "Figure 2 from our paper\n\n\nNow that our paper is out in the Lancet Regional Health Americas, I wanted to write up a blog post talking about it.\n\nOur paper is available free and open access here: https://www.thelancet.com/journals/lanam/article/PIIS2667-193X(22)00201-0/fulltext\n\n\n\nscreenshot of our article in the Lancet Regional Health Americas\n\n\nOne of the main contributions this paper makes is that it considers above and beyond the voter lean of the public what the impact of political ideology of US House and Senate representatives may have been during the first year in which vaccines were widely available for adults (April 2021–March 2022).\nPart of what made this work possible was having the data available on Congressional representative’s political ideology/leaning available from Voteview.com which applies a principle components analysis type approach to Congressional representatives’ votes on individual bills. This allowed us to incorporate information not just on whether representatives were Republican or Democratic, but the degree to which they leaned Republican or Democratic.\n\n\n\nScreenshot from Voteview.com showing the distribution of political ideology\n\n\nWe included a quite substantial list of county level covariates, described fully in the captions to our figures in the article. Click on the below images to see the full resolution versions.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigure 2 depicted the bivariate relationships between COVID-19 mortality, ICU capacity, and several of our most important covariates stratified by state trifecta status (i.e., whether the House, Senate, and Governorship were all controlled by the same party or divided).\n\nFigures 3 and 4 showed how various political ideology metrics were associated with our outcomes of interest either in univariate relationships (model 1), after adjusting for demographic and social metrics (like median age, log population density, percent below poverty, the Index of Concentration at the Extremes for Racialized Economic Segregation, and racial/ethnic composition) (model 2), after additionally adjusting for all of the other political metrics (model 3), after further adjusting for vaccination (model 4), and after adjusting for risk factors like the percent with obesity and diagnosed with diabetes (model 5). Essentially this follows the logic of starting out with an un-adjusted analysis that compares the outcomes (age standardized COVID-19 mortality and ICU occupancy) with each of the political metrics one-at-a-time in model 1 and then adds on additional variables sequentially going from model 2 to 5 to illustrate how much of the effect associated with political ideology may be explained by associations with other measured factors.\nOne of the things that I think is so great about this paper is that it provides an almost perfect followup to some of our previous work, The Evolving Roles of US Political Partisanship and Social Vulnerability in the COVID-19 Pandemic from February 2020 - February 2021 both in terms of the subject-matter of focus and the time-periods being studied. I think it’s particularly nice that we were able to study the February 2020-February 2021 time-period as a timeframe during which trends in the pandemic were largely driven by factors unrelated to vaccination, and to follow that up with a separate paper focused on March 2021-April 2022 when vaccines were a much larger part of the picture.\n\n\n\nIn that paper we put much more emphasis on the role of voter lean (as in the political lean of the population residing within each county) rather than the political lean of representatives. For example, figure 3 from that paper drove home the point that the relationship between voter lean and COVID-19 mortality was changing as the pandemic progressed.\n\n\n\nThis blog post isn’t about that paper, but I think the two papers are worth reading together.\nOne final word on this is that I’d just like to say it’s been extremely gratifying seeing our work pay off. At one point the press release written about our article was on the cover of the Harvard T.H. Chan School of Public Health website, and our article appears at the top of the list in the Most Read articles of the Lancet Regional Health Americas. Publicity isn’t everything, but it’s nice to see that our article is reaching a wide audience and hopefully advancing thought on the political determinants of public health.\nOnce again, the links to these two articles:\n\nRelationship of political ideology of US federal and state elected officials and key COVID pandemic outcomes following vaccine rollout to adults: April 2021–March 2022\nThe Evolving Roles of US Political Partisanship and Social Vulnerability in the COVID-19 Pandemic from February 2020 - February 2021"
  },
  {
    "objectID": "posts/2023-06-10-Scale-Dependent-Rendering-Maps.html",
    "href": "posts/2023-06-10-Scale-Dependent-Rendering-Maps.html",
    "title": "Scale (Zoom) Dependent Maps with Leaflet in R",
    "section": "",
    "text": "Something I’ve wanted to accomplish for a while is producing interactive maps in R that provide a higher level of resolution as the user zooms in.\nI’ve finally sat down and accomplished that, and I’m quite happy to be sharing the R code here.\nSince I live in the Boston area and have family in the New York area, I thought those were great examples to start with, but the code should be easily adaptable to any US state or locale that has data collected in the American Community Survey.\n# dependencies\nrequire(leaflet)\nrequire(sf)\nlibrary(tidycensus)\nlibrary(tidyverse)\nlibrary(tidyr)\nlibrary(magrittr)\nlibrary(leafpop)\nlibrary(htmlwidgets)\nlibrary(leaflet.extras)\n\noptions(tigris_use_cache = TRUE)\n# median income, age, and pct in poverty in Boston Area ---------------------------------------------------\n\n# download county data\nma_counties &lt;- get_acs(\n  geography = \"county\",\n  state = \"MA\",\n  variables = c(\n    median_income = \"B19013_001\",\n    median_age = \"B01002_001\",\n    total_for_poverty = \"B17101_001\",\n    in_poverty = \"B17101_002\"\n  ), \n  year = 2021,\n  geometry = FALSE\n)\n\n# download tract data\nma_tracts &lt;- get_acs(\n  geography = \"tract\",\n  state = \"MA\",\n  variables = c(\n    median_income = \"B19013_001\",\n    median_age = \"B01002_001\",\n    total_for_poverty = \"B17101_001\",\n    in_poverty = \"B17101_002\"\n  ), \n  year = 2021,\n  geometry = FALSE\n)\n\n# download block group data\nma_block_groups &lt;- get_acs(\n  geography = \"block group\",\n  state = \"MA\",\n  variables = c(\n    median_income = \"B19013_001\",\n    median_age = \"B01002_001\",\n    total_for_poverty = \"B17101_001\",\n    in_poverty = \"B17101_002\"\n  ), \n  year = 2021,\n  geometry = FALSE\n)\n\n# put the data together in a list\nma_geographic_dfs &lt;- list(\n  counties = ma_counties,\n  tracts = ma_tracts,\n  block_groups = ma_block_groups\n)\n\n\n# pivot the data wider\nma_geographic_dfs %&lt;&gt;% purrr::map( ~ tidyr::pivot_wider(\n  .,\n  id_cols = c('GEOID', 'NAME'),\n  names_from = 'variable',\n  values_from = 'estimate'\n))\n\n# calculate the pct in poverty from last 12 months of household income poverty threshold data\nma_geographic_dfs %&lt;&gt;% purrr::map( ~ mutate(., pct_in_poverty = in_poverty / total_for_poverty * 100))\n\n# add geography data to each: \n# we held off on doing this in the `tidycensus::get_acs` calls because sf objects \n# often interact poorly with `tidyr::pivot_wider`\nma_geographic_dfs$counties &lt;-\n  left_join(\n    tigris::counties(\n      cb = TRUE,\n      resolution = '20m',\n      state = 'MA'\n    ),\n    ma_geographic_dfs$counties,\n    by = c('GEOID' = 'GEOID')\n  )\n\nma_geographic_dfs$tracts &lt;-\n  left_join(\n    tigris::tracts(cb = TRUE, state = 'MA'),\n    ma_geographic_dfs$tracts,\n    by = c('GEOID' = 'GEOID')\n  )\n\nma_geographic_dfs$block_groups &lt;-\n  left_join(\n    tigris::block_groups(cb = TRUE, state = 'MA'),\n    ma_geographic_dfs$block_groups,\n    by = c('GEOID' = 'GEOID')\n  )\n\n\n# this formatter is so that the data we show in the `leafpop::popupTable` renders nicely \ncustom_formatter &lt;- function(df) {\n  \n  # use the scales::*_format functions to provide nice formatting\n  df$median_income %&lt;&gt;% scales::dollar_format()()\n  df$median_age %&lt;&gt;% scales::number_format()()\n  df$pct_in_poverty %&lt;&gt;% scales::percent_format(scale = 1, accuracy = .1)()\n\n  # we don't want to be sending lists of boundary coordinates into the popupTable\n  df %&lt;&gt;% sf::st_drop_geometry()\n  \n  # some quick renaming & selection of only important variables\n  df %&lt;&gt;% select(\n    GEOID,\n    NAME = NAME.y,\n    `Median Age` = median_age,\n    `Median Income` = median_income,\n    `Poverty` = pct_in_poverty\n  )\n\n  return(df)\n}\n\n# we'll use Blues for the income level\nincome_pal &lt;- colorNumeric(\"Blues\", domain = ma_geographic_dfs$block_groups$median_income, na.color = NA)\n\nleaflet() %&gt;%\n  addProviderTiles(providers$CartoDB.Voyager) %&gt;%\n  addPolygons(\n    data = ma_geographic_dfs$counties,\n    fillColor = ~income_pal(median_income),\n    weight = 0,\n    color = \"white\",\n    fillOpacity = 0.7,\n    group = 'counties',\n    popup = leafpop::popupTable(custom_formatter(ma_geographic_dfs$counties), row.numbers = F)) %&gt;%\n  addPolygons(\n    data = ma_geographic_dfs$tracts,\n    fillColor = ~income_pal(median_income),\n    weight = 0,\n    color = \"white\",\n    fillOpacity = 0.7,\n    group = 'tracts',\n    popup = leafpop::popupTable(custom_formatter(ma_geographic_dfs$tracts), row.numbers = F)) %&gt;%\n  addPolygons(\n    data = ma_geographic_dfs$block_groups,\n    fillColor = ~income_pal(median_income),\n    weight = 0,\n    color = \"white\",\n    fillOpacity = 0.7,\n    group = 'block groups',\n    popup = leafpop::popupTable(custom_formatter(ma_geographic_dfs$block_groups), row.numbers = F)) %&gt;%\n  addLegend(\n    data = ma_geographic_dfs$block_groups,\n    pal = income_pal,\n    values = ~median_income,\n    opacity = 0.7,\n    title = \"Median Income $\",\n    labFormat = labelFormat(prefix=\"$\"),\n    position = \"bottomright\"\n  ) %&gt;%\n  addFullscreenControl() %&gt;% \n  groupOptions(\"block groups\", zoomLevels = 13:20) %&gt;% # this is where the magic (scale/zoom dependent rendering happens)\n  groupOptions(\"tracts\", zoomLevels = 10:12) %&gt;%\n  groupOptions(\"counties\", zoomLevels = 1:9) -&gt;\n  ma_income_map\n\nhtmlwidgets::saveWidget(ma_income_map, file = \"ma_income_map.html\", selfcontained = FALSE)\n\n\npoverty_pal &lt;- colorNumeric(\"Reds\", domain = ma_geographic_dfs$block_groups$pct_in_poverty, na.color = NA)\n\nleaflet() %&gt;%\n  addProviderTiles(providers$CartoDB.Voyager) %&gt;%\n  addPolygons(\n    data = ma_geographic_dfs$counties,\n    fillColor = ~poverty_pal(pct_in_poverty),\n    weight = 0,\n    color = \"white\",\n    fillOpacity = 0.7,\n    group = 'counties',\n    popup = leafpop::popupTable(custom_formatter(ma_geographic_dfs$counties), row.numbers = F)) %&gt;%\n  addPolygons(\n    data = ma_geographic_dfs$tracts,\n    fillColor = ~poverty_pal(pct_in_poverty),\n    weight = 0,\n    color = \"white\",\n    fillOpacity = 0.7,\n    group = 'tracts',\n    popup = leafpop::popupTable(custom_formatter(ma_geographic_dfs$tracts), row.numbers = F)) %&gt;%\n  addPolygons(\n    data = ma_geographic_dfs$block_groups,\n    fillColor = ~poverty_pal(pct_in_poverty),\n    weight = 0,\n    color = \"white\",\n    fillOpacity = 0.7,\n    group = 'block groups',\n    popup = leafpop::popupTable(custom_formatter(ma_geographic_dfs$block_groups), row.numbers = F)) %&gt;%\n  addLegend(\n    data = ma_geographic_dfs$block_groups,\n    pal = poverty_pal,\n    values = ~pct_in_poverty,\n    opacity = 0.7,\n    title = \"% in Poverty\",\n    labFormat = labelFormat(suffix=\"%\"),\n    position = \"bottomright\"\n  ) %&gt;%\n  addFullscreenControl() %&gt;% \n  groupOptions(\"block groups\", zoomLevels = 13:20) %&gt;%\n  groupOptions(\"tracts\", zoomLevels = 10:12) %&gt;%\n  groupOptions(\"counties\", zoomLevels = 1:9) -&gt;\n  ma_poverty_map\n\nhtmlwidgets::saveWidget(ma_poverty_map, file = \"ma_poverty_map.html\", selfcontained = FALSE)\n\n\nage_pal &lt;- colorNumeric(\"magma\", domain = ma_geographic_dfs$block_groups$median_age, na.color = NA, reverse = TRUE)\n\nleaflet() %&gt;%\n  addProviderTiles(providers$CartoDB.Voyager) %&gt;%\n  addPolygons(\n    data = ma_geographic_dfs$counties,\n    fillColor = ~age_pal(median_age),\n    weight = 0,\n    color = \"white\",\n    fillOpacity = 0.7,\n    group = 'counties',\n    popup = leafpop::popupTable(custom_formatter(ma_geographic_dfs$counties), row.numbers = F)) %&gt;%\n  addPolygons(\n    data = ma_geographic_dfs$tracts,\n    fillColor = ~age_pal(median_age),\n    weight = 0,\n    color = \"white\",\n    fillOpacity = 0.7,\n    group = 'tracts',\n    popup = leafpop::popupTable(custom_formatter(ma_geographic_dfs$tracts), row.numbers = F)) %&gt;%\n  addPolygons(\n    data = ma_geographic_dfs$block_groups,\n    fillColor = ~age_pal(median_age),\n    weight = 0,\n    color = \"white\",\n    fillOpacity = 0.7,\n    group = 'block groups',\n    popup = leafpop::popupTable(custom_formatter(ma_geographic_dfs$block_groups), row.numbers = F)) %&gt;%\n  addLegend(\n    data = ma_geographic_dfs$block_groups,\n    pal = age_pal,\n    values = ~median_age,\n    opacity = 0.7,\n    title = \"Median Age\",\n    position = \"bottomright\"\n  ) %&gt;%\n  addFullscreenControl() %&gt;% \n  groupOptions(\"block groups\", zoomLevels = 13:20) %&gt;%\n  groupOptions(\"tracts\", zoomLevels = 10:12) %&gt;%\n  groupOptions(\"counties\", zoomLevels = 1:9)  -&gt;\n  ma_age_map\n\nhtmlwidgets::saveWidget(ma_age_map, file = \"ma_age_map.html\", selfcontained = FALSE)"
  },
  {
    "objectID": "posts/2017-03-19-Qualtrics-Tools.html",
    "href": "posts/2017-03-19-Qualtrics-Tools.html",
    "title": "QualtricsTools : Automated Survey Processing",
    "section": "",
    "text": "QualtricsTools is an open source application built in R Shiny that I started while working at Tufts that allows users to upload a Qualtrics JSON QSF Survey File, and response data in CSV format and automatically calculate tables and frequencies custom to the survey’s questions types, format, and responses.\n\n  QualtricsTools, an R web-app\n\nThe project is now maintained by Emma Morgan at Tufts – so check out the her GitHub repository for more information."
  },
  {
    "objectID": "posts/2021-12-26-Yearly-Recap.html",
    "href": "posts/2021-12-26-Yearly-Recap.html",
    "title": "2021 in Review",
    "section": "",
    "text": "I couldn’t really talk about 2021 without mentioning that I got married in June 2021!"
  },
  {
    "objectID": "posts/2021-12-26-Yearly-Recap.html#i-got-married",
    "href": "posts/2021-12-26-Yearly-Recap.html#i-got-married",
    "title": "2021 in Review",
    "section": "I got married!",
    "text": "I got married!\nOur photographer, Tamara, did a great job taking photos of our ceremony. Here are some of my favorites."
  },
  {
    "objectID": "posts/2021-12-26-Yearly-Recap.html#published-papers-and-working-papers",
    "href": "posts/2021-12-26-Yearly-Recap.html#published-papers-and-working-papers",
    "title": "2021 in Review",
    "section": "Published papers and working papers",
    "text": "Published papers and working papers\nI had a number of published papers and working papers. Some of the work I’m the most proud of include work in a preprint we shared on The Evolving Roles of US Political Partisanship and Social Vulnerability in the COVID-19 Pandemic from February 2020 - February 2021.\nAll of my articles are listed on my Google Scholar page, but I particularly appreciated the emphasis that our Evolving Roles article had on considering competing models. Testing competing model implementations is one of the 10 “not so simple” rules for credible practice of modeling and simulation identified by the Committee on Credible Practice of Modeling and Simulation in Healthcare seeded from a U.S. interagency initiative in this article."
  },
  {
    "objectID": "posts/2021-12-26-Yearly-Recap.html#photography",
    "href": "posts/2021-12-26-Yearly-Recap.html#photography",
    "title": "2021 in Review",
    "section": "Photography",
    "text": "Photography\nI’ve been taking photography a lot more seriously this year and I’m proud of the results. I think I’ve taken some stunning shots and I enjoy looking at them, so I hope others do too."
  },
  {
    "objectID": "posts/2021-12-26-Yearly-Recap.html#my-new-puppy-hodu",
    "href": "posts/2021-12-26-Yearly-Recap.html#my-new-puppy-hodu",
    "title": "2021 in Review",
    "section": "My New Puppy Hodu",
    "text": "My New Puppy Hodu\nOf course I would be remiss if I didn’t mention my new puppy Hodu.\nHe is quite the character."
  },
  {
    "objectID": "posts/2021-12-26-Yearly-Recap.html#ideas-for-2022",
    "href": "posts/2021-12-26-Yearly-Recap.html#ideas-for-2022",
    "title": "2021 in Review",
    "section": "Ideas for 2022",
    "text": "Ideas for 2022\nI hope that in 2022 we all strive to create a better world. I want to see those who are intent to build a more equitable and sustainable world empowered to do so. I want to see humanity build and implement a better future. I would ask if that’s too much to ask for, but I don’t think it is."
  },
  {
    "objectID": "posts/2022-10-01-phdgp2.html",
    "href": "posts/2022-10-01-phdgp2.html",
    "title": "The Public Health Disparities Geocoding Project 2.0",
    "section": "",
    "text": "The Public Health Disparities Geocoding Project 2.0 was a workshop where my colleagues and I trained 150 Public Health professionals from diverse backgrounds (city and state health departments, advocacy organizations, policy think-tanks, academia, non-profits, etc.) on how to use geo-referenced data for analyses that promote health equity.\nI am so proud of what we were able to accomplish in this training in terms of recruiting participants from such diverse backgrounds, selecting them from out of over 500 applicants, and designing workshops for them that met them where they were no matter their skill level or area of focus.\n\n  \n\nThe workshops emphasized myriad topics including best practices for disease mapping, spatial modeling of disease rates, data visualization, and how to structure health communication in a way that actively combats the stigmatization of marginalized groups.\nOne of the ways that we were able to meet participants needs no matter their background was through the deliberate structuring of distinct areas of emphasis throughout the course. The three areas of emphasis that we identified that individuals could choose to focus on depending on their personal experience and background were:\n\nInterpretation: How do we interpret the measures and analytic results we construct? To whom do they apply? How can we describe the motivation and need for the methods we employ?\nData Wrangling & Coding: How do we use programming code to construct our measures and models of interest? How do we deal with idiosyncracies in the data like numerator/denominator mismatch?\nCommunication: What are the best approaches for communicating with different kinds of stakeholders? How do we leverage color most appropriately in data visualization while being inclusive to those with color-blindness? How do we craft our messages to avoid stigmatizing places and populations?\n\nEach of these three tracks are reflected in the posters that we designed to accompany our workshop and training manual.\n\n\n\n  \n\n\n  \n\n\n\n\n\n\n\n\nSpeaking of our training manual, all of our workshop materials are fully free and open-access online contained in our training manual available at https://phdgp.github.io/PHDGP2.0/index.html.\n\n\n\nThe training manual was created in R using the bookdown package by Yihui Xie.\nIn case you’re looking for the data that goes with each of the case studies, those are available here: https://www.hsph.harvard.edu/thegeocodingproject/save-the-date-the-public-health-disparities-geocoding-project-2-0/\nLastly, I just want to share that the videos from our trainings are available online.\n\n\n\n\n\n\n\n\nLinks:\n\nThe Public Health Disparities Geocoding Project 2.0 Training Manual\nPHDGP 2.0 background, data links, faculty listing\nHarvard Featured News Story: Project uses geographic data to show that where a person lives matters to their health"
  },
  {
    "objectID": "posts/2020-10-06-HOPE-Summary.html",
    "href": "posts/2020-10-06-HOPE-Summary.html",
    "title": "HOPE 2020",
    "section": "",
    "text": "HOPE 2020 took place July 25th through August 2nd and for the first time ever was all-online due to the COVID-19 pandemic. I’ve written up this summary of my seven favorite talks with some links to read more about their content matter.\n\nTable of Contents: - 75,000 FOIA Requests Can’t be Wrong - Free As In Dirt: In Pursuit of Truly Open Source Physical Objects - Librarians and Crisis Response: The Case of COVID-19 Maker Response - The Election System - Can We Fix It? Yes, We Can! - One Ring to Rule Them All - Solarpunk, Cyberpunk, and Popculture - Keynote by Jaron Lanier\n\n\n75,000 FOIA Requests Can’t be Wrong\n\n\nMichael Morisy founded MuckRock to help requesters file FOIA requests. He said he described their service as “like TurboTax for FOIA requests, until we realized everyone hates TurboTax.”\n\n\n\nScreenshot of MuckRock website\n\n\nWhat started out as an attempt to get public records out of the Somerville, Massachusetts local government turned into the realization that with enough sustained effort through FOIA requests, the public could pressure the government into being more transparent, often even proactively so. After over a decade of automating the process for submitting FOIA requests, they’ve unearthed some pretty interesting stuff.\nCheck out some of their most interesting work:\n\nUnearthing CREST: CIA’s Declassified Archives\nPolice Surveillance: Facial Recognition Use in Your Backyard\n\nAlong the way, MuckRock and FOIA Machine have created the online open-source DocumentCloud service which is now one of the industry standard online document hosting services with analysis, annotation, and publishing capabilities. DocumentCloud is used at places like the NY Times, ProPublica, PBS, The Guardian, and others. DocumentCloud runs every document you upload through Thomson Reuters OpenCalais, giving you access to extensive information about the people, places and organizations mentioned in each.\nLinks: - https://www.muckrock.com/ - https://www.foiamachine.org/ - https://www.documentcloud.org/ - Atlas of Surveillance: Documenting Police Tech in Our Communities\nLink to Talk\n\n\nFree As In Dirt: In Pursuit of Truly Open Source Physical Objects\n\n\n\n\n\nTitle slide for Free As In Dirt by Dominic Muren\n\n\n3D printers and CNC machines have revolutionized who has access to the ability to custom part making capabilities, but it still requires financial investment and access to global supply chains for parts and materials. Further, even since the advent of these technologies, globalized supply chains are, if anything, stronger than ever.\nOne key reason for this is that though these machines print with digital instructions which can be easily copied and sent, the materials they use is specialized, and therefore usually centrally produced. Another is that many of these materials are mined, or harvested in a mining-like way, so centralized production is most cost-effective.\nThis talk presented an alternative technological development path: one where materials are sourced entirely from constituents of living ecologies - plants, animals, microbes, and the materials they produce. Starting with historical examples of ecology-derived material production, Dominic presented a catalogue of possible materials for experimentation. Then, using examples drawn from the maker community and from his own work, he showed how this method of production has the potential to make objects with functional properties across the entire spectrum of complexity - even including simple electronics. The talk emphasized the importance of pursuing manufacturing systems with societal and ecological advantages as well as resilience.\n\n\n\nthe challenge, how to reimagine manufacturing so that every object made reinforces healthy ecologies where humans co-habitate\n\n\nMotivating principle: While vegetarians and vegans are well known for arguing that we should prioritize eating foods which are closer to the bottom of the food chain to be more sustainable, where is the physical materials analogue of this philosophy? Such a philosophy could emphasize consuming materials which have low atomic numbers.\nUnfortunately the materials which humanity is so hungry for (gold, rare earth minerals, coltan, etc.) are high in atomic number and are primarily extracted from the environment via environmentally devastating mining projects. Moreover, our hunger for metals like coltan which is used in transistors has had disastrous impacts on humanity including financing conflict in the Democratic Republic of Congo.\nWith coltan and other rare earth minerals being principle ingredients in silicon chip based electronics, it seems unlikely that even with recycling and a reduction in humanity’s rapacious desire for these minerals that we could ever get to 0 consumption soon. However, a hypothetical alternative to mining does exist that deserves investigation: phytoremediation.\nShocking as it may seem, there exist plants that are still being discovered which naturally accumulate metals from the soil in which they grow. The New Caledonian tree Pycnandra acuminata accumulates 20-25% nickel in the latex it produces, and as a result the tree even appears to bleed blue-green.\n\n\n\n Photo Credit: The discovery of nickel hyperaccumulation in the New Caledonian tree Pycnandra acuminata 40 years on: an introduction to a Virtual Issue\nPerhaps combined with the advancement of a global environmentalist agenda, these phytoaccumulators could provide an alternative to the mining which has been both negatively impacting political stability and the environment.\nIt’s not just phytoremediation that offers a glimpse into an alternative, ecologically friendly reality that we could create: there are technologies such as those used at WholeTrees.com which are already being implemented in practice that dramatically reduce the need for lumber in construction projects. WholeTrees.com provides mechanical and structural engineers with an interface to specify their exact dimensional and structural needs and their software matches them with trees whose structure already matches their needs.\n\n\n\nPavillions constructed from trees supplied through WholeTrees.com, showing off how purpose-chosen trees can suit the architectural and structural needs of a given situation exactly\n\n\nTrees aren’t the only green construction material that poses great potential for upending our wasteful, toxic modern practices: This Is Grown is a project started by designer and researcher Jen Keane to develop fabrication techniques that make use of k. rhaeticus bacteria to perform ‘microbial weaving’ with cellulose. The bacteria produce a material that is both strong and lightweight with little to no wastage.\n  Photo Credit: Jen Keane – This is Grown\nOther environmentally friendly efforts are even more custom-fit: Row7 Seeds is a company breeding fruits and vegetables exactly suited to consumer needs, whether it’s growing single-serving size vegetables to reduce restaurant waste or creating crops which are catered specifically to the growing environments in a single farm. They were recently featured in a New York Times op-ed, Save Our Food. Free The Seed. I’m happy that Row7 Seeds exists as an alternative model for agriculture that someday could pull us away from the grip of Monsanto.\n\n\n\nscreenshot of the row7 website\n\n\nNewly developed environmentally friendly business practices don’t just stop at purpose-bred seeds and purpose-fit trees: an entire community has cropped up around the idea of Open Source Ecology. They even have a Wiki. Open Source Ecology provides all of the information and schematics one needs to start building and promoting high-performance, modular, do-it-yourself, low-cost, sustainable civilization and the machinery necessary for it.\nSee also:\n\nThe Land Institute who are working to disrupt our currently monoculture-based agriculture with polycultures and perennial crop based agricultures.\nThe Block Research Group at ETH Zürich who are working to develop new construction techniques which are more efficient, economical, and expressive with the aim to draw inspiration from our architectural heritage and reduce greenhouse gas emissions. Read their paper “Redefining Structural Art: strategies, necessities and opportunities” for an introduction to their working philosophy.\nTeachable Sorter - a cheap, Raspberry Pi powered teachable sorter that enables low-budget projects to make use of machine-learning and computer-vision powered sorting.\nDominic Murien’s homepage\nDominic Murien’s TED Fellows feature: Break it down and make it\n\nLink to Talk\n\n\nLibrarians and Crisis Response: The Case of COVID-19 Maker Response\n\n\nFrom the talk description directly:\n\nOn Thursday, March 19, 2020, Dr. Pierre Elias, a Columbia University cardiology fellow, reached out to Research and Learning Technologies librarian Madiha Choksi to utilize the Columbia University Libraries’ 3D printers to produce supplemental face shields. Within a few days, she had optimized an existing design for face shields, taken two 3D printers from Butler Library to her apartment, and was printing parts and assembling shields. A few days later, she was joined by her fellow librarians, Alex Gil and Moacir P. de Sá Pereira. Two months later this team of librarians had organized one of the largest PPE grassroots efforts in the city, COVID Maker Response, which effectively produced and distributed more than 25,000 face shields to New York City hospitals and other front line institutions during the height of the city’s pandemic crisis.\n\n\n\n\nColumbia Studio Libraries website screenshot\n\n\nThe Columbia University Libraries Studio has been engaged in disaster response efforts for years now, not only with their most recent COVID-19 response efforts, but also through their Nimble Tents Toolkit which provides research and documentation to help teams organize and address urgent challenges.\nThe work Columbia University Libraries Studio has been doing in response to COVID-19 has undoubtedly made a great impact, but I think I’d like to focus here on what I learned about how they’ve been able to translate their learned knowledge into guidance and resources for others working in urgent crisis response situations through the Nimble Tents Toolkit.\n\n\n\nNimble Tents Toolkit website screenshot\n\n\nThe Nimble Tents Toolkit coordinated a mapathon immediately after Hurricane Maria in 2018 to document the damage experienced during Hurricane Maria enabling crisis responders to target their response efforts efficiently and effectively. Such mapathons are now more commonplace and facilitated by MissingMaps.org, an organization that uses OpenStreetMaps to document the most vulnerable places in the world, so that international and local organizations can use the maps and data to better respond to crises.\nThe Nimble Tents Toolkit also provides direction on how to conduct Rapid Response Research (RRR). Their guidelines not only discuss the practicalities of how to conduct RRR but also how to promote the findings through open access web-based communications, how to use Nimble Data Management practices to make data and models most effective once publicly released, how to prepare for media and publication releases, and how to deal with some of the hidden costs of RRR.\nThe Nimble Tents Toolkit also pays special attention to how to develop Flash Subject Guides that can serve to quickly bring researchers and activists onboard when a crisis requires urgent response. Their guide not only discusses what content should be included, but also how its maintenance can be best organized depending on your team, best practices, how to ensure accessibility, and a catalogue of Flash Subject Guides.\nLastly, the Nimble Tents Project hosts a description of how the Maryland Institute for Technology in the Humanities hosted a Night Against Hate social media event on October 13th, 2016 to gather and learn how to investigate and work to resist hate speech on social media. They partnered with the Southern Poverty Law Center and made use of their Extremist Files which is a database documenting the profiles of prominent extremists and extremist organizations. The description on the Nimble Tents Project website describes the motivation, foundations, methods, and post-event analysis that was conducted. One of the primary products of the Night Against Hate is a CSV-formatted block list that allows users to easily block known extremists and extremist organizations from appearing on users’ Twitter feeds.\nSee Also: Online To Online, or O2O, provides online accessible training for anybody interested in learning more about how to organize community action.\nLink to Talk\n\n\nThe Election System - Can We Fix It? Yes, We Can!\n\n\n\n\n\nscreenshot of bia-sci-lab title slide\n\n\n13 year old founder and CEO of Girls Who Hack, Bianca Lewis, or Bia, of BiaSciLab presented on the security inadequacies in our election system and how we can fix them.\nOffering solutions which not only address current inadequacies (such as the rampant potential for SQL injection and other forms of tampering in our election reporting system), Bia promotes solutions which will prevent future insecurity such as bug bounty programs, open source software and hardware, hand marked paper ballots, encryption, and risk-limiting audits.\nBia is working on Secure Open Vote, and end-to-end election system built on modern, open source software and hardware.\n\n\n\nscreenshot of secure-open-vote website\n\n\nShown below, Bia has recently presented her work at the U.S. Congressional Hearing on Election Security and at security conferences all over the world.\n\n\n\nbia standing with the election security commission\n\n\nSee also: the Securing America’s Federal Elections or S.A.F.E. Act\nLink to Talk\n\n\nOne Ring to Rule Them All\n\n\n\n\n\nFigure 1 from Calacci’s extended abstract: county density map of ring cameras per capita in the 48 states\n\n\nDan Calacci, Figure 1: County density map of Ring cameras that posted to the Ring Neighbors app since 2017\nDan Calacci from the MIT Media Lab is turning Amazon Ring’s surveillance in on itself. Using the Ring Neighbors app, Calacci has aggregated data not only on where Ring has the strongest presence and what kind of video footage it has been collecting, but also how users interact with that footage, annotating it and reporting it as containing “suspicious activity.”\nIn one particular appalling example, Calacci showed us footage posted to a forum for Jamaica Plain residents (Jamaica Plain being just south of Boston, Massachusetts) of what appear to be children roller-blading and playing in the street. This video was shared on social media and posted by the owner of the recording Ring device as an example of suspicious activity, with the poster exclaiming that it documented potential car-jacking activity (not at all supported by the video).\nCalacci went on to interrogate this idea of whether or not Amazon Ring’s system is actually documenting crime, and even if it is, to question the effect that residents policing their neighbors could have.\nIn an extended abstract submitted to the 6th International Conference on Computational Social Science, Calacci documented the results of a spatial autoregressive lag model of the data he collected. In this paper he finds that less expensive, middle-income neighborhoods with comparatively low home values are more likely to use the Ring platform. Surprisingly, theft was not significantly correlated with the number of Ring cameras per county, but other crimes including robbery and motor vehicle theft were.\n\n\n\nfigure 2 from calacci’s paper: coefficients from the sarlm regression model\n\n\nDan Calacci, Figure 2: Total (direct + indirect) impact of county-level variables on number of active Ring cameras,corrected for spatial autocorrelation and estimated using a spatial simultaneous autoregressive model\nHis work is featured in this recent Gizmodo article: Ring’s hidden data let us map amazon’s sprawling home surveillance network.\nIn recent work, Calacci has been examining measures of how much more complicated traveling through a given city like Boston would get if one wanted to completely avoid potentially being recorded on a Ring camera.\nLink to Talk\n\n\nSolarpunk, Cyberpunk, and Popculture\n\n\n\n\n\nSolarpunk: A Promise, Not a Warning\n\n\n Art Credit: 白色风车 by Liuying J.P\nThis talk explored the problematic themes and biases of modern popular narratives around technology. As technology becomes more complex and sophisticated, people more and more on stories about technology to understand the tech-world. Unfortunately these stories are often produced by multi-national, well-marketed corporations that have an incentive in furnishing their stories with hidden product ads, lone genius-inventor legends, and cyberpunk visions of a world with no privacy (but so much convenience)!\nSadly, cyberpunk is the default story when it comes to modern science fiction. Our popular movies focus on technology as a means to create greater weapons, and the characters cast as the heroes are all too often heroes simply because they take the situation into their own hands. Instead, it is possible to imagine a version of sci-fi where democratizing technology allows the public to prevent the consolidation and weaponization of technology. This is part of what solarpunk is.\nSolarpunk emphasizes an optimistic vision of the future where humankind works together with technology to address environmental concerns such as climate change and pollution.\nSolarpunk promotes the Repair Manifesto as a rejection of over-consumption.\n\n\n\nthe repair manifesto\n\n\nHere’s my favorite quote from the talk, referring to the Iron Man movies and how these portrayals of technology contribute to the loss of our ability to ask about how technology can be used for the whole of society:\n\nHey Mr. Stark, why don’t you create small energy generators for every hospital worldwide? In Syria they could really use it right now.\n\nSee Also: solarpunks.net a neat blog about solarpunk progress.\nLink to Talk\n\n\nKeynote by Jaron Lanier\n\n\nThis talk was primarily rhetorically and didactically driven, so for brevity I’ve included an outline for anybody in a rush.\nOutline:\n\nAn increasingly common theme of current media is that people are afraid of being replaced:\n\nThis is because of the often perpetuated narrative that human laborers are like widgets or parts of a machine in the modern economy.\n\nThis philosophy hasn’t worked out very well for productivity and quality.\nThis kind of thinking has been successfully upended where human laborers have been given more agency in their roles as manufacturers.\n\nSee Deming and statistics’ in role quality control.\n\n\nSo looking at more contemporary problems, shouldn’t humans be given more agency in regards to AI and how their personal data is used?\n\nThis could be achieved through collective bargaining and responsibility.\n\nThis might help empower content producers as well as put a stop to the promotion of inflammatory media that engages our fight-or-flight response.\n\nSee unionization, Gareem Bank and solidarity lending.\n\n\n\nWhat about addressing the fact that the AI as a black box continues to scare people?\n\nLooking at it from its roots, the narrative that computer intelligence is separate from human intelligence is driven by our instincts to fear that which we don’t understand as well as narcissism in viewing computer-scientists as some kind of god-like creators of new intelligence.\nWe should emphasize that the alternative is to view computer intelligence not as artificial intelligence, but as augmented/associative/aggregate intelligence.\n\nMaybe if more people understood this perspective, they would be less scared of an AI-driven economic collapse.\nSee possible alternative data collection methods, like the Microsoft Trove which wants to pay people to license their data for use by researchers training computer models.\n\n\n\n\nLanier spoke about the increasingly common subtext in popular media that humanity is being threatened by being replaced by technology.\nLanier argues that this narrative is fed to us constantly through social and traditional media – including examples of ostensibly optimistic news articles describing how machine-learning algorithms can now outperform skilled experts, such as doctors in identifying particular diseases like cancers.\nFirst, to put this idea in context, let’s trace its cultural origins. Much of this notion of humanity being replaced by technology first took root with the industrial revolution. The prevailing viewpoint was that human laborers on the factory lines were replaceable and they worked as if they were pre-specified parts of a machine with no agency or autonomy. However, this system had a problem: it didn’t work very well, because workers weren’t invested in the outcome of their work.\nA new practice and philosophy in manufacturing soon disrupted this mentality, and this came from William Edwards Deming, who was among other things an engineer and statistician. Deming was one of the first to introduce statistics into manufacturing practices, and in particular an early advocate for real-time feedback loops. The theory goes that as a result of sharing quality assessments with workers, workers become more invested in the quality of their product.\nDeming’s teachings were first widely adopted in Japan during the post-war period. Ford Motor Company was simultaneously manufacturing transmissions for a new car in both Japan and the United States. After the car made it to market, consumers quickly started requesting the model with Japanese transmissions over the US-made transmissions. When Ford engineers decided to inspect for differences between the transmissions made in the US vs. Japan, they found that while those made in the US were within the specified tolerance ranges, the Japanese were virtually identical to each other and closer to the nominal values for each part. As a result, the Japanese transmissions ran smoother.\nWhat does this tell us about the relationship we should strive for between people and technology in the modern world? In fact, many of the same problems of poor quality control and lack of investment are happening with machine learning and data aggregation. People don’t know how their data are being used and lack any reason to be invested in the results of machine learning projects based on data collected from sources such as social media.\nThere are many ways that data are aggregated, but one of the most common is a barter relationship where people are told “give us your data, and in return we’ll provide you some service. (e.g. social media).”\nUnfortunately, this sends the message that the intelligence is in the algorithm and not in the data and it removes the role of human intelligence in data collection.\nSo what can we do about it? Is it conceivable to imagine a world where people have awareness of what data they’re producing, the ability to influence what happens with it, and some ability to improve it if it’s to a purpose?\nOne source of inspiration is how workers not only gained agency through not only manufacturing practices but also through unionization.\nLanier proposes the notion of Mediators of Individual Data, or MIDs. A MID would represent a cohort of individuals who band together and collectively advocate for controlled usage of their data.\nAs an example of how free-association based groups can effectively advocate for their interests together, look at the track record of Gareem Bank in Bangladesh.\nMuhammad Yunus, founder of Gareem Bank, won the Nobel Peace Prize in 2016 for his research and work on solidarity lending as a means to provide banking services to the rural poor without collateral.\nSolidarity lending has been around for a while, and it’s not without valid criticism, but the fundamental idea of using group cohesion to reduce risk and establish trust seems to hold water.\nIn any large-scale learning environment, Lanier argues, there has to be some coarse-grained mechanisms. In evolution, we call it a species: we don’t just have one evolutionary lineage that tries to solve everything. In a neural network, it’s individual layers.\nCurrently, social media exists without that coarse-grainedness – it’s just the provider vs. individuals. Without the distributed mechanisms of group-level trust, and group-level attention to decency and quality, we have created a world where inflammatory media that ignites our fight-or-flight response prevails.\nEven if we were to successfully give people collective bargaining and responsibility in the context of social media, there’s still this pervasive view of compuer intelligence as a threat to human laborers.\nThis comes down to a question of how computer intelligence is viewed: is it separate from our own intelligence, as if a mind of its own, or is it an extension of humanity, like a tool?\nLanier argues gives two reasons why the “AI” side of this divide, where computers are viewed as intelligent independent and separately from human intelligence, may have won the star role in popular culture narratives. 1). It plays into the fear of the other, and that can be used to yield funding. That is to say, when one approaches a military agency and tells them Skynet is going to come alive, and whoever controls it is going to control the world, they’re pretty fast to hand over their money. 2). The other side of this is that it’s flattering to think of humans as giving birth to some kind of new life-form, as if we can play god.\nInstead, if we were to recast AI from meaning “artificial intelligence”, to denoting aggregate, associative, and augmented intelligence – a form of intelligence which people work together to create with the understanding of technology as a human activity, rather than as a threat to humanity – perhaps people would feel more optimistic about their ability to contribute in shaping the future.\nOne possible model of how a future where people are given more respect and agency in the aggregation of data used for machine learning projects is Microsoft Trove. Trove provides users the ability to license their images and data to machine learning projects in exchange for a small payment while still getting to own their data. By providing an opportunity for researchers in need of data and those producing the data to interact, the Trove project aims to ethically and respectfully produce high quality machine learning datasets.\nLink to Talk"
  },
  {
    "objectID": "posts/2018-05-24-getting-started-in-r.html",
    "href": "posts/2018-05-24-getting-started-in-r.html",
    "title": "Resources for R Programmers",
    "section": "",
    "text": "This is a set of resources for people interested in the R programming language.\nI have designed it with the intention and hope that it will be useful to people of all skill levels from completely new to programming to subject matter experts who might be interested in expanding their horizons.\nEvery link below is completely free to use. \n\n\nBeginner Resources\nBefore diving into the R programming language, I would highly recommend installing the RStudio development environment. It makes a lot of interactions with the R programming language and peripheral programming related tasks (version controlling, connecting to databases, code-formatting, etc.) much easier.\nIf you’re a beginner and you want to get started with R as fast as possible, I recommend the following guides:\n\nSwirl : Learn R, in R - Swirl allows newcomers to start interacting with the R programming language through guided tutorials primarily aimed at beginners.\nLearn X in Y Minutes : R - Learn X in Y Minutes walks readers through an example script which demonstrates many of the important R language features without getting too bogged down on any specific topic. This is a great quick reference for the syntax of R.\nR Language for Programmers - If you have any experience programming but are new to R, or would simply like a quick refresher on the basic language features of R, this is a good reference.\nCookbook for R - This website (and its corresponding book) provide examples and tutorials on many of the most common tasks that programmers are accomplishing with R.\n\nLastly, I want to encourage people to use the help.start() feature in R. Open the R console, type help.start(), and hit enter. A window will open which allows you to view the R manuals, check out packages’ documentation, and search for keywords on R-specific sites and resources.\nKeep in mind that you can always use ?command or help() to look up help without leaving your R or RStudio session.\n\n\n\nMore Technical Resources\nOnce you have an understanding of the basics in R, at some point you will likely want to understand how to write better code instead of code that barely meets your needs. The following resources will help you understand the design and motivations behind the R programming language and will, in turn, will help you become a better R programmer:\n\nAn Introduction to R - This introduction to R is quite comprehensive and technical. I should point out that while other guides may discuss packages outside the base R language, this introduction focuses entirely on the base R language. Many people will recommend that it is important to understand the base R language, and then to quickly move onto using the nearly self-contained ecosystems implemented in packages like the tidyverse,\naRrgh, a newcomer’s (angry) guide to R - aRrgh takes the stance that as R is a programming language predominantly developed by statisticians and not programmers, it has some very quirky and at times outright offensive features. Despite this, R comes with tools and ideas that make it uniquely suitable for statistical data analysis and after learning its quirks many people find R to be an indespensible tool they frequently reach for. aRrgh is a guide on those quirks and “gotchas.”\nThe R Inferno - “If you are using R and you think you’re in hell, this is a map for you.”\nR-Bloggers : Tutorials for Learning R - R-Bloggers is a popular website among R users where R tutorials and blogposts are aggregated and widely distributed. This is a great post, similar to this one of mine, delineating resources in an ordering suitable for newcomers to the R language.\nEfficient R Programming - This book takes a dive into the topic of writing R code which is efficient while keeping the prerequisite knowledge of the language to a minimum.\nR Packages - R Packages are an integral part of the R ecosystem, and it is considered good practice to format your work as a package where possible due to the many added perks gained from R’s package development tools.\nAdvanced R - Advanced R takes a closer look at the technical features of the R programming language to help users improve their R programming skills.\nThe R Manuals - The R Manuals from CRAN are for those who want to take a deep dive into the fundamentals of the R programming language. In particular, I recommend checking out The R Language Definition and R Internals if you really want to understand how R works.\n\n\n\n\nTopic-Specific Resources\nWhile having an understanding of R’s internals and subtleties to some degree is important, it’s also important to get things done. Depending on your interests or needs, here are some resources that you might find helpful:\n\nGeneral Purpose\n\nRStudio’s Cheat Sheets - RStudio’s Cheat Sheets are great at-a-glance reference cards for many of the popular packages and features of R. They have ones for many topics, including base R, the RStudio development environment, ggplot2, a data visualization package, and many, many more.\nCRAN’s Task Views - CRAN’s Task Views organize packages into topics to make them more easily discoverable.\nAwesome-R - Awesome R is a curated list of R packages and tools which helps with discovering new and popular packages to help you accomplish a given task.\nR Graphics Cookbook - This resource appears as if it is just one chapter inside the R Cookbook already linked above, but in actuality it is a whole book on its own dedicated to the subject of producing graphics and plots with R. This book makes heavy use of ggplot2, one of the most popular graphics frameworks which employs a theory of the grammar of graphics to make writing code to produce graphics more natural and straightforward.\nRcpp, Rcpp-introduction, and the Rcpp vignettes - Rcpp is a package which provides a seamless interface between C++ and R. This is a great utility for speeding up projects in R\n\n\n\nData Science\n\nR for Data Science - R for Data Science, or R4DS, is a very popular book in the R community which teaches users to perform statistical analyses, visualize them, and to communicate their results effectively using the tools the R community has to offer.\nText Mining with R : A Tidy Approach - Another popular topic these days is natural language processing. Text Mining with R introduces ideas on how one can use the tidy data paradigm to ease their textual analyses.\nThe Elements of Statistical Learning: Data Mining, Inference, and Prediction is the 2nd edition of a popular, mathematically rigorous, treatment of statistical learning with R examples. The PDF of the book is available for free, and a real gift to the community.\nForecasting: Principles and Practice - This text introduces methods for forecasting with timeseries data using techniques including auto-regressive methods, dynamic regression, hierarchical modeling, and others.\nSpatial Data Science - This reference is a great place to get started with learning how to map and manipulate spatial data in R. The text covers a wide variety of applications that will help you to make outstanding geographical data visualizations.\nSpatio-Temporal Statistics with R - This book covers statistical techniques in a very hands-on way for dealing with data that have geographical or geo-temporal dimensions to them. The methods covered include both descriptive and dynamic modeling techniques as well as a treatment of model checking, selection, and validation for spatio-temporal models.\nFeature Engineering and Selection: A Practical Approach for Predictive Models - This reference is all about improving predictive performance for your models through the construction of more informative features from your original dataset. These materials will help you to be better able to address aspects of your data like interactions, nonlinear relationships, missingness, noisiness and the need for variable selection.\nSurrogates: Gaussian Process Modeling, Design and Optimization for the Applied Sciences - This text focuses on the simulation of physical processes with a mathematical and statistical perspective. The practical data-driven examples contained herein provide a great reference for those who need to fit models that reflect complex real-world processes with computational efficiency.\nAnalyze Survey Data for Free - This text covers how to work with survey microdata in R from a variety of sources. Not only is it great at presenting important survey related methodologies like how to use weighting to produce descriptive statistics, visualizations, and regression models, but it also serves as a great reference of survey data that’s out there freely available for your social science research needs.\n\n\n\nShiny and Web Development\n\nShiny from RStudio - Shiny is a web framework for R with ever-improving documentation and articles. Shiny makes it easy for users to interact with data analyses through web-interfaces that functions through a reactive programming paradigm.\nShow Me Shiny - In addition to the references available on RStudio’s website for Shiny, I also highly recommend the examples available at showmeshiny.com. These showcase many nontrivial and novel use-cases for Shiny and can often serve as inspirational material.\nEngineering Production-Grade Shiny Apps - If you need to build shiny apps that will be reliable and robust for large numbers of users, this is the book for you.\nhtmlwidgets for R - Create JavaScript based widgets to render interactive data visualizations within R."
  },
  {
    "objectID": "posts/2021-06-17-boston-photography.html",
    "href": "posts/2021-06-17-boston-photography.html",
    "title": "Boston Night Skyline",
    "section": "",
    "text": "I just wanted to share this really nice photo I took of the Boston skyline in the last couple weeks.\nEnjoy!"
  },
  {
    "objectID": "posts/2017-03-18-Introduction-to-Elliptic-Curves.html",
    "href": "posts/2017-03-18-Introduction-to-Elliptic-Curves.html",
    "title": "Introduction to the Theory of Elliptic Curves",
    "section": "",
    "text": "Elliptic curves are a subject, simple to construct and ubiquitous, that have found themselves at the forefront of Number Theory and Algebraic Geometry research. The subject has roots in some of the oldest Mathematics, and its modern connections tie it to an incredible span of research including fluid flow, sphere packing, modular forms, and string theory. Elliptic curves are the degree three nonsingular algebraic plane curves with at least one rational point.\n\n\n\nTheir existence was considered by Diophantus in the 2nd century a.d. in his text Arithmetica. The question he originally posed has been rephrased in modern language: “To divide a given number into two numbers such that their product is a cube minus its side.” That is, given \\(a \\in \\mathbb N\\) find \\(x,y \\in \\mathbb Z\\) such that \\[y(a-y) = x^3 - x.\\]\n\nElliptic curves were the topic of my undergraduate thesis, which you can download  here.\nMost individuals are familiar with the plane conics, the degree two nonsingular algebraic curves. Elliptic curves, in some sense, are their slightly more complicated, yet seemingly infinitely more subtle, older sibling. This will be realized later through the concept of genus.\nElliptic curves are contemporarily thought of as plane curves, however they originally arose in the context of calculating arc-lengths of ellipses. It is these arc-lengths of ellipses which in part created elliptic curve’s early ubiquity. These are the elliptic integrals\n\\[ \\int R(t,\\sqrt{P(t)}) dt, \\]\nwhere \\(P(t)\\) is a degree three or four nonsingular polynomial and \\(R\\) is a rational function of \\(\\sqrt{P(t)}\\) and \\(t\\). An example might be derived from the pendulum, such as:\n\\[ \\int \\frac{d\\theta}{\\sqrt{C + \\cos \\theta}} =\n- \\int \\frac{dx}{\\sqrt{(1-x^2)(C+x)}} =\n\\int \\frac{dx}{y}, \\text{ where } y^2 = (1-x^2)(C+x).\\]\nApollonius first considered calculating the arc-length of an ellipse around 200 b.c. and found that he was unable to do it. This problem defied progress until the 17th century when Euler and others found infinite series expressions for arc-lengths. Further, Euler discovered as surprising group law for these infinite series.\n\\[ \\int_{\\infty}^{x_1} \\frac{dx}{y} + \\int_{\\infty}^{x_2} \\frac{dx}{y} =\n\\int_{\\infty}^{x_3} \\frac{dx}{y}.\\]\nIn 1687 Newton wrote down the majority of Bezout’s Theorem, which states that given two irreducible degree curves their intersection counting multiplicity has the product of the degrees of the curves. This gave algebraic motivation for what had already been observed: there is group structure to the rational points of an elliptic curve.\n\n\n   Point Addition and Multiplication\n\n\nElliptic integrals, before connecting to elliptic curves, were inverted and considered as elliptic functions by mathematicians such as Abel, Gauss, Jacobi, and notably Weierstraß. The motivation for doing so is that the inverse of \\(\\int \\frac{dx}{\\sqrt{1-x^2}} = \\arcsin(x)\\) is significantly more friendly a function.\nWhile it may be that Diophantus considered solutions to the equation describing an elliptic curve, their modern formulation rests on their analytic construction as the doubly periodic functions over \\(\\mathbb C\\). These are Weierstraß’ elliptic functions\n\\[\\wp:\\mathbb C \\to \\mathbb C / \\Lambda \\text{ for some } \\Lambda \\cong\n\\mathbb Z\\omega_1 +\\mathbb Z\\omega_2,\\]\n\\[ \\wp(z \\; \\omega_1,\\omega_2) = \\frac{1}{z^2} + \\sum_{n^2+m^2 \\ne 0} \\left( \\frac{1}{(z+m\\omega_1+n\\omega_2)^2} -\\frac{1}{\\left(m\\omega_1+n\\omega_2\\right)^2} \\right)\n,\\]\n\\[\\wp(z) = \\frac{1}{z^2} + \\sum_{\\omega \\in \\Lambda - \\{ 0\\} } \\left( \\frac{1}{(z-\\omega)^2} -\\frac{1}{\\omega}^2 \\right),\\]\nwhere \\(\\omega_1\\) and \\(\\omega_2\\) generate the complex lattice \\(\\Lambda = \\{ \\mathbb Z \\omega_1 + \\mathbb Z \\omega_2 \\}\\), or if \\(\\omega_2\\) is normalized to 1, simply \\(\\Lambda = \\mathbb Z \\omega + \\mathbb Z\\).\n\n\n    Weierstraß’ \\(\\wp\\) function.\n\n\nIndeed, what these mathematicians surrounding the 18th Century had discovered is that calculating arc-lengths of ellipses naturally involved thinking about the problem in an algebraically closed field such as the complex numbers \\(\\mathbb C\\), where the problem is translated to one with doubly periodic structure. This structure is isomorphic to that of a torus. One way to think of this is by “identifying edges.” If \\(z\\) drifts of the top of the fundamental parallelogram, its image re-appears on the bottom of the parallelogram under a doubly periodic function, and similarly for drifting over the side. This is stating that as a Riemann surface an elliptic function have a topology with a single hole, like a torus, and that it has genus \\(g = 1\\). This suggests a major separation in the theory of elliptic curves from those of conics, since the conics are genus zero curves.\nWeierstraß discovered that all doubly periodic functions could be expressed through his \\(\\wp\\) function, and that it followed the differential equation:\n\\[ \\wp' (z)^2 = 4 \\wp^3 (z) -g_4 \\wp (z) - g_6,\\]\nwhere \\(g_4 = 60G_4\\) and \\(g_6 = 140G_6\\) and \\(G_n\\) is Eisenstein’s series given by \\[ G_n = \\sum_{\\omega \\neq 0} \\frac{1}{\\omega^n}.\\]\nCorresponding to this complex doubly periodic structure, Weierstraß had found a way to classify the equations of elliptic curves. Any degree three nonsingular algebraic plane curve over a field \\(k\\) can be transformed to Weierstraß form:\n\\[y^2 = x^3 + ax + b, \\text{ provided } \\text{characteristic}(k) \\neq 2,3,\\]\n\\[\\text{ and always at least } y^2 + a_1 xy + a_3y = x^3 + a_2x^2 + a_4 x + a_6 \\text{ even if } \\text{characteristic}(k) = 2,3. \\]\nIndeed, Elliptic Curves defined over the complex numbers \\(\\mathbb C\\) are isomorphic to complex lattices given by \\(\\mathbb C / \\Lambda\\) for a lattice \\(\\Lambda\\). Startling connections were born of this fact.\nThe Eisenstein series are examples of modular forms, which are incredibly deep number theoretical objects, described by complex functions which satisfy certain invariance properties under their arguments translation by particular matrix groups. Elliptic Curves are a seemingly simple class of curves, with a natural group law arising from Bezout’s theorem and Algebra-Geometric arguments, and yet we have found that they are tied into Number Theory in profound and unanticipated ways.\nTo a Weierstraß equation is associated two useful invariants: the \\(j\\)-invariant and the \\(\\Delta\\) discriminant. Klein’s \\(j\\)-Invariant is among other things, a representative of the elliptic curve’s isomorphism class over the algebraically closure, and the discriminant is a polynomial defined as a product such that when a polynomial has factors with multiplicity it vanishes, that is to say \\(\\Delta = 0\\) when the curve is singular.\nThese are found to have the following equations\n\\[ \\Delta=g_2^3-27g_3^2, \\]\n\\[ j(\\tau) = 1728 \\frac{g_2^3}{\\Delta}. \\]\n\n\n   The \\(j\\)-Invariant as a modular form \n\n\n\nThe 20th Century saw great progress in Algebraic-Geometry and as a result an elliptic curve’s rational points, denoted \\(E(\\mathbb Q)\\), are somewhat better understood. In 1922 the Mordell-Weil Theorem was proven, which states that all abelian varieties over number fields are finitely generated abelian groups. Later in 1984 a conjecture by Mordell was proven by Faltings stating that the genus 0 curves over \\(\\mathbb Q\\) have either \\(\\emptyset\\) or infinitely many points, genus 1 curves have \\(\\emptyset\\), finitely many, or infinitely many \\(\\mathbb Q\\)-points.\nHowever, simultaneous progress was being made in the theory of Modular Forms. Ramanujan defined his \\(\\tau\\) function by the power series expansion of the discriminant \\(\\Delta\\).\n\\[\\sum_{n\\geq 1}\\tau(n)q^n=q\\prod_{n\\geq 1}(1-q^n)^{24} =\\Delta(z),\\]\n\\[\\text{ where } q=\\exp(2\\pi iz).\\]\nRamanujan was able to conjecture powerful number theoretic congruences describing this \\(\\tau\\) function through modular forms. Separately Ramanujan used Eisenstein series and other modular forms to produce astounding congruences describing the partition function \\(p(n)\\), the function which counts the ways a whole number can be partitioned not counting ordering. The following have been established as theory.\n\\[ \\begin{align}\n\\tau(mn) = \\tau(m) \\tau(n) \\text{ if } m \\text{ and } n \\text{ are relatively prime,} \\\\\n\\tau(p^{r + 1}) = \\tau(p)\\tau(p^r) - p^{11}\\tau(p^{r - 1}), \\\\\n|\\tau(p)| \\leq 2p^{11/2} \\text{ for primes } p. \\\\\n\\end{align} \\]\n\\[ \\begin{align}\np(5k+4) & \\equiv 0 \\pmod 5 \\\\\np(7k+5) & \\equiv 0 \\pmod 7 \\\\\np(11k+6) & \\equiv 0 \\pmod {11}.\n\\end{align} \\]\n\n\n\n   Image Credit: The Concinnitas Project \n\n\n\n These are some of the most beautiful congruences in Number Theory and Mathematics. In a 1972 lecture by Freeman Dyson on the Missed Opportunities between Mathematics and Physics, he begins with the story of the following MacDonald equation for Ramanujan’s Tau Function. The MacDonald Equation is an astonishing formula, but to have also found connections to physics highlights the depth to which Ramanujan’s \\(\\tau\\)-function, born out of the discriminant \\(\\Delta\\), reaches into the abstract world.\nIn the early 1990s Andrew Wiles established the Modularity Theorem, an equivalence between modular forms and the rational structure of an elliptic curve \\(E(\\mathbb Q)\\), and consequently proved Fermat’s Last Theorem. After the 20th Century, Elliptic Curves have found themselves amidst deep Number Theory whilst being employed in applications from cryptography to engineering. The Birch and Swinnerton-Dyer conjecture remains open, and we have yet to fully understand the rank of the group \\(E(\\mathbb Q)\\). Elliptic Curves may have been with us from the very origins of algebra, but we are still just beginning to understand their tremendous structure.\n\nSources\n\nAlice Silverberg : Ranks Cheat Sheet\nDale Husemöller : Elliptic Curves\nEzra Brown and Bruce T. Myers : Elliptic Curves from Mordell to Diophantus and Back\nFreeman Dyson : Missed Opportunities\nJ.S. Milne : Elliptic Curves\nJoseph H. Silverman : Advanced Topics in the Arithmetic of Elliptic Curves\nJoseph H. Silverman : Elliptic Curves\nNeal I. Koblitz : Elliptic Curves and Modular Forms\nSilverman and Tate : Rational Points on Elliptic Curves\nTom M. Apostol : Modular Functions and Dirichlet Series in Number Theory"
  },
  {
    "objectID": "posts/2023-02-13-success-in-id529.html",
    "href": "posts/2023-02-13-success-in-id529.html",
    "title": "The first offering of ID529 Data Management and Analytic Workflows in R at Harvard",
    "section": "",
    "text": "Teaching ID529 was such a blast, and I’m so happy with how the course turned out. The students have repeatedly communicated that they learned an extraordinary amount, that the skills they learned will be tools and frameworks of thinking they take forward with them as they continue their research and scholarship, and that they appreciated the down-to-earth, fun, affirmative atmosphere we fostered in our classroom.\nIn Fall 2022, my colleague, mentor, and supervisor Jarvis Chen asked me if I wanted to teach a course about R for the Population Health Science (PHS) PhD program at Harvard. This request came about because the PHS students had expressed in prior years’ surveys an uncomfortability with programming and that their coursework gradually transitioned from not expecting them to be able to program to suddenly expecting them to be able to program with no instruction on the topic. Based on the lectures on Exploratory Data Visualization for Longitudinal Data Analysis, my work founding, lecturing for and coordinating the R User Group at the Harvard Data Science Initiative, and lecturing at the Public Health Disparities Geocoding Project 2.0 Jarvis thought I was a good choice for an instructor and the right person to design the course curriculum.\nWe formed an absolutely fantastic teaching team between Jarvis, myself, Dean Marengi, and Amanda Hernandez with everyone contributing to create what I think became a fantastic course. Our course website is online here https://id529.github.io/, so a lot of the logistical details and overview material (including our slides and lecture recordings) is best accessed on there, but I thought I’d take some space here to talk about what I thought really made this course different."
  },
  {
    "objectID": "posts/2023-02-13-success-in-id529.html#course-tracks",
    "href": "posts/2023-02-13-success-in-id529.html#course-tracks",
    "title": "The first offering of ID529 Data Management and Analytic Workflows in R at Harvard",
    "section": "Course Tracks",
    "text": "Course Tracks\nFirstly, I think we were completely committed to creating an affirmative environment for the students. We emphasized for our students that there were different “tracks” through which one could take this whirlwind of a two-week short-course, and those were\n\nBeginner/Novice\nData Visualization\nData Cleaning/Management and Working with Codebooks\nProgramming and Software Engineering\nOther Niche Topics in R\n\nWe were emphatic about communicating that we just wanted to see that students challenged themselves to grow through the in-class work and homework, and did as much as we possibly could to take the pressure and anxiety of grades off the table. We were sure to provide constructive and encouraging feedback on their work, but for the most part as long as we saw that students were making a good-faith effort to learn new skills we were eager to give them As on their work and in the class so they could focus on learning, not worrying about grades."
  },
  {
    "objectID": "posts/2023-02-13-success-in-id529.html#affirmations",
    "href": "posts/2023-02-13-success-in-id529.html#affirmations",
    "title": "The first offering of ID529 Data Management and Analytic Workflows in R at Harvard",
    "section": "Affirmations",
    "text": "Affirmations\nSeveral days throughout the course, we took time out of class to go over these affirmations designed to help combat imposter syndrome. One student told me that this was a refreshing change from the “sink-or-swim” Python programming classes they had encountered elsewhere, and they had incorporated these statements into their morning meditation practice — which I consider an absolute win!\n\n\n\nHere are some affirmations that can help you to reframe your thoughts and let go of any negative self-doubt or impostor syndrome that you may be feeling. I am capable and competent. I am worthy and deserving of success. I trust in my abilities and the effort I put forth. I am enough, exactly as I am. I am learning and growing with each challenge I face. It’s important to remember that everyone experiences moments of self-doubt and uncertainty, and it’s okay to not feel confident all the time. The key is to recognize and acknowledge those feelings, and then remind ourselves of our strengths and capabilities."
  },
  {
    "objectID": "posts/2023-02-13-success-in-id529.html#memes",
    "href": "posts/2023-02-13-success-in-id529.html#memes",
    "title": "The first offering of ID529 Data Management and Analytic Workflows in R at Harvard",
    "section": "Memes",
    "text": "Memes\nThroughout the class, we were sure to use a lot of wholesome memes — and I suppose that might seem kind of silly at first glance, but I think it helped create a fun, vibrant atmosphere where tensions were lowered and people felt like it was OK to make a mistake!\n\n\n\nsome memes used in class"
  },
  {
    "objectID": "posts/2023-02-13-success-in-id529.html#real-time-feedback-surveys",
    "href": "posts/2023-02-13-success-in-id529.html#real-time-feedback-surveys",
    "title": "The first offering of ID529 Data Management and Analytic Workflows in R at Harvard",
    "section": "Real-Time Feedback Surveys",
    "text": "Real-Time Feedback Surveys\nAnother aspect in which we were different from the usual class was our goal from the outset to correct and gauge how the course was going as we went along. We circulated surveys with the students on the first day and then again on the third day that allowed us to check what the students were most eager to get out of the class, how they thought it was going, and whether they thought we should change the pacing at all. Most students thought that the pacing was a little fast, so we worked to slow down the curriculum for the remainder of the course, adding more time for discussion and making sure we focused on the fundamentals and essentials so that our students would get the most bang-for-their-buck (their buck being the tuition they pay Harvard and the opportunity cost associated with the time they spent in our classroom as opposed to anywhere else in the world they could be enjoying themselves).\nThough we did have some standard run-of-the-mill Qualtrics surveys we gave to the students, we also had some interactive real-time Menti surveys that both the students and instructors really enjoyed.\n\n\n\na bunch of bubbles representing the backgrounds of each of our students\n\n\n\n\n\nsurvey results asking the students about what skill level they are, with cat gifs representing each level\n\n\nI was really surprised at just how appreciative the students were. When we were honest about asking them to bear with us as we were teaching the course for the first time, some students said they felt privileged to be part of the inaugural class. Similarly, as a result of asking students to fill out surveys to gauge how the students were feeling, the students expressed appreciation that we were willing to change the pacing of our course to meet them where they’re at."
  },
  {
    "objectID": "posts/2023-02-13-success-in-id529.html#github-classroom",
    "href": "posts/2023-02-13-success-in-id529.html#github-classroom",
    "title": "The first offering of ID529 Data Management and Analytic Workflows in R at Harvard",
    "section": "GitHub Classroom",
    "text": "GitHub Classroom\nOne of our major goals was to teach the students how to use GitHub and get them actively using it during the timeframe of the course — so to us, it made sense to use GitHub Classroom to share assignments as template repositories that students could build off of. That said, it was a very new process for those of us on the teaching team and we weren’t entirely certain how it would go. That said, I think it went fantastically! It was absolutely incredible to see how willing the students were to learn how to use GitHub, many often pushing themselves to set things up the “right way” (with SSH-key authentication) and learning Git commands even though there are buttons for most basic functions available in RStudio. It was really fantastic to see students who had never even thought about using GitHub going all the way from setting up accounts, creating repositories, and thoughtfully using markdown to document and supplement the code in their homework repositories.\n\n\n\nscreenshot of GitHub classroom repository"
  },
  {
    "objectID": "posts/2023-02-13-success-in-id529.html#google-docs",
    "href": "posts/2023-02-13-success-in-id529.html#google-docs",
    "title": "The first offering of ID529 Data Management and Analytic Workflows in R at Harvard",
    "section": "Google Docs",
    "text": "Google Docs\nOne of the things that worked incredibly well for facilitating class discussions was sharing a Google Doc that students could ask questions in anonymously and the instructional staff or lecturer would respond as soon as they could during class. This made it so students didn’t have to feel shy about if their questions would make them look foolish or silly or anything like that, but instead to ask anything that they thought might be beneficial for them to hear about. Students communicated to us in their feedback that they really appreciated this mode of Q&A!\n\n\n\nexample of one of the days google docs"
  },
  {
    "objectID": "posts/2023-02-13-success-in-id529.html#hodu",
    "href": "posts/2023-02-13-success-in-id529.html#hodu",
    "title": "The first offering of ID529 Data Management and Analytic Workflows in R at Harvard",
    "section": "Hodu",
    "text": "Hodu\nIn an effort to keep things light and upbeat, we incorporated my charming dog Hodu as much as possible, which students cheered and celebrated to a degree that made me so happy we had thought to include him.\n\n\n\nfour slides from the class featuring Hodu tips\n\n\nWe even brought Hodu to school to let the students enjoy being in his presence for a while. I think the students who stuck around that Friday evening really enjoyed meeting him and his brother Sabre who my wife and I were also petsitting at the time.\n\n\n\nhodu doing ‘piggyback’ on my back\n\n\nSome students even incorporated Hodu into their final projects in creative ways. One of my favorites was one student’s innovation on the Hodu Tip concept — when describing something a programmer shouldn’t do, they said that be more of a “No-du Tip”!\n\n\n\none of the slides from our student presentations"
  },
  {
    "objectID": "posts/2023-02-13-success-in-id529.html#fun-activities",
    "href": "posts/2023-02-13-success-in-id529.html#fun-activities",
    "title": "The first offering of ID529 Data Management and Analytic Workflows in R at Harvard",
    "section": "Fun Activities",
    "text": "Fun Activities\nWe wanted to make sure that we didn’t have the students just sitting for four hours every day, so we were sure to break things up with stretch-breaks and occasionally structured activities. One of my favorite activities we came up with was a QR-code based activity where students scanned QR codes in the hallway that linked them to datasets that contained “secret messages.” Once they got their datasets and instructions, they had to figure out how to uncover the secret message using ggplot2 and possibly some mathematical or programmatic transformations of the data.\n\n\n\nPopulation Health Science Rules\n\n\n\n\n\nIf the first line of your script is setwd I will come into your office and set your computer on fire\n\n\nThe second of these messages comes from this famous tidyverse.com blogpost by Jenny Bryan: https://www.tidyverse.org/blog/2017/12/workflow-vs-script/\nOne activity that I particularly enjoyed was the “Bonus Extra Credit” on their first assignment with ggplot2 where we encouraged them to “Fancy Your Figure”. We did this because we believe that when you channel your creative instincts and focus on bending ggplot2 to your will, you end up learning a lot along the way including aspects of ggplot2 that you might not otherwise learn so soon and which may prove useful to you.\nOne student’s submission was particularly fantastic, and I have to give them props for committing so hard to their concept.\n\n\n\nDepression status by age in the NHANES sample; the background has Elmo on fire, the colors are red themed, and the text is in an old gothic style font\n\n\nAnother activity that I think had everybody enthralled was a Shiny-app simulated Rock Paper Scissors Lizard Spock tournament in which we gave away a copy of the R for Data Science book by Hadley Wickham and Garrett Grolemund!\n\n\nThe code behind the app are available on my GitHub here: https://github.com/ctesta01/RPSLS/ and the app is online here: https://ctesta.shinyapps.io/RPSLS/"
  },
  {
    "objectID": "posts/2023-02-13-success-in-id529.html#course-outcomes",
    "href": "posts/2023-02-13-success-in-id529.html#course-outcomes",
    "title": "The first offering of ID529 Data Management and Analytic Workflows in R at Harvard",
    "section": "Course Outcomes",
    "text": "Course Outcomes\nBesides the students performing spectacularly and giving stellar final presentations, we also collected measurable data through our first-day and final survey on how comfortable students felt with each of the key skills the course aimed to teach.\n\n(For the above figure, you might want to Right Click -> Open Image In New Tab to see it full screen).\nNot only is there a visible shift in students’ reported comfort level across these different skills, but this shift turns out to be statistically significant in every case. I’m so proud of how much our students learned!\n\nLastly, we asked students how likely they are to recommend the course to a friend, and the students who responded to our survey were overwhelmingly likely to encourage their friends to take the class, with almost 90% saying they would strongly recommend the class."
  },
  {
    "objectID": "posts/2024-05-12-Bhramar-Mukherjee-Marvin-Zellen-Award.html",
    "href": "posts/2024-05-12-Bhramar-Mukherjee-Marvin-Zellen-Award.html",
    "title": "Bhramar Mukherjee’s Marvin Zelen Award Talk",
    "section": "",
    "text": "This last Thursday (May 9th, 2024), Bhramar Mukherjee received the annual Marvin Zelen Award from the Harvard Biostatistics Department.\nSometimes a talk leaves you with enough food for thought that you simply have to write down the highlights somewhere you know you can come back to them, and Dr.  Mukherjee’s certainly fits the bill.\nHer talk was on Data Equity in Health Research.\n\nOn the nascency of the field:\nShe asks the question: when was the first textbook in statistics written, soliciting guesses from the audience. The answer is in Agresti, A. (2023). A historical overview of textbook presentations of statistical science. Scand J Statist, 50(4), 1641–1666. https://doi.org/10.1111/sjos.12641.\nShe also highlighted Janet Norwood several times throughout her talk, emphasizing the quote, “Women have to take advantage of the opportunities presented to them; it often isn’t quite as straight a career path as it is for men.”\nThe point, from how I understood it, is that our field of (bio-)statistics is still finding its way — and we all in it have an active role in shaping what that will be.\n\nOn Marvin Zelen and his legacy:\n“What remains after papers and awards fade away are people and culture.”\nShe argues that though critical work was done by Marvin Zelen, the truly impactful legacy in is effect on the department — making it a welcoming place, intellectually curious, and emphasizing “statistical science” — that the field cannot be just methods, but must be grounded in science too.\n\nOn the racial/ethnic makeup of biobank/genetics study participants:\nShe showed this figure from Fatumo, S., Chikowore, T., Choudhury, A. et al. A roadmap to increase diversity in genomic studies. Nat Med 28, 243–250 (2022). https://doi.org/10.1038/s41591-021-01672-4\n\n\n\nA graph showing side-by-side the proportion of genetic database participants by racial/ethnic group with the world composition; white/european populations are overrepresented, while Southeast Asian are barely visible in genetic database cohorts.\n\n\nDriving home the point, she pointed out to us that her parents are Indian and hence in the barely represented South Asian portion of the above graph, and asked “When will my parents have access to precision medicine?”\n\nOn data inequities:\nCiting LaVeist (2023), she points out the economic loss due to racial/ethnic disparities. Even if one sets aside the (paramount, crucial, necessary) moral arguments about health justice, there is an undeniable economic toll attributable due to preventable disparities in marginalized vs. privileged groups.\nLaVeist TA, Pérez-Stable EJ, Richard P, et al. The Economic Burden of Racial, Ethnic, and Educational Health Inequities in the US. JAMA. 2023;329(19):1682–1692. doi:10.1001/jama.2023.5965\nChunara, R., Gjonaj, J., Immaculate, E., Wanga, I., Alaro, J., Scott-Sheldon, L. A. J., et al. (2024). Social determinants of health: The need for data science methods and capacity. Volume 6, Issue 4, e235-e237. https://doi.org/10.1016/S2589-7500(24)00022-0\nThis motivates her work in thinking about how to fully capture the myriad causes that actually drive health in her research.\n\nShe described the ‘vicious cycle’ that health-affecting algorithms can enter, where existing disparities and systemic discrimination bias training datasets, biasing algorithms, affecting real-life access to resources, intervention, and disadvantaging already disadvantaged communities, leading to a perpetuation of the cycle.\n\n\n\nConceptual Framework for Applying Guiding Principles to Mitigate and Prevent Bias Across an Algorithm’s Life Cycle. This conceptual framework builds on a National Academy of Medicine algorithm life cycle framework adapted by Roski et al.\n\n\nMarshall H. Chin, et al. Guiding Principles to Address the Impact of Algorithm Bias on Racial and Ethnic Disparities in Health and Health Care. JAMA Network Open. 2023;6(12):e2345050. doi:10.1001/jamanetworkopen.2023.45050\nThese data inequities, distinct from and also deeply intrinsically tied to health inequities, are part of what Dr. Mukherjee calls “The Data Struggle of the Unseen” [1, 2]\nTo the end of upending these vicious cycles, she cites the work on guidelines for mitigating risk in health-system algorithms: Collins, G. S., Dhiman, P., Andaur Navarro, C. L., Ma, J., Hooft, L., Reitsma, J. B., Logullo, P., Beam, A. L., Peng, L., Van Calster, B., van Smeden, M., Riley, R. D., & Moons, K. G. (2021). Protocol for development of a reporting guideline (TRIPOD-AI) and risk of bias tool (PROBAST-AI) for diagnostic and prognostic prediction model studies based on artificial intelligence. BMJ open, 11(7), e048008. https://doi.org/10.1136/bmjopen-2020-048008\n\nOn the work of Marvin Zelen and Stephen Lagakos, and their legacy in community-engaged work:\nIn the late 70s and 80s, Marvin Zelen, Stephen Lagakos and others led a series of analyses on the effects of contaminated well-water in Woburn, MA.\n\nKnown as the Harvard Health Study, the investigation showed, for the first time, a connection between Woburn’s contaminated water and a variety of adverse health effects, including leukemia. The matter made headlines, wound up in court, and was chronicled in the book A Civil Action, which was later made into a movie. As the book notes, when Prof. Zelen announced the study’s results in the basement of a Woburn church in February 1984, someone in the audience called out, “Thank God for Marvin Zelen,” and the crowd burst into applause.\n\nFrom https://www.hsph.harvard.edu/news/features/in-memoriam-prof-marvin-zelen-a-tremendous-force-in-biostatistics/\n\n\n\nFigure from 1986, JASA, Shaded map of Woburn showing levels of exposure to contaminated wells\n\n\nSee https://sphweb.bumc.bu.edu/otlt/mph-modules/woburnleukemia/Lagakos_et_al_Woburn.pdf for a copy of one of the original papers.\nCoincidentally, in 2023 the EPA just proposed a ban on one of the chemicals identified in the Lagakos et al study\nMukherjee relates Zelen and Lagakos’ community-engaged work to her own fieldwork-focused projects in India related to maternal-health. When confronted by her academic advisor who said something along the lines that “this isn’t biostatistics!” She says she said back, “Well, sorry, but you have tenured me.”\nShe seemed to admonish some tenured faculty, saying “why do you play it so safe?” Why don’t you take a risk?\nLater during the talk, she said that there is a common refrain “Statistician’s play in everyone’s backyard, but I am not happy with just a backyard. I want a front-yard, a garden, a forest.” Meaning, it’s easy for statisticians to lament the quality of the data they’re given, but she sees this as an impetus to get involved and improve study-design and data-collection from its conception.\n\nOn the effects of doing data-equity focused work on her career:\nDriven by a lack of quality reporting on COVID-19 in India, Mukherjee and colleagues did quite a lot of early and sustained writing about the pandemic.\nShe recalled a story of meeting a couple in an airport in India who recognized her and said that they based their decision on when to move their parents from one city to another based on her work. This, for her, was a clear and powerful example of how she was making a real difference in peoples’ lives.\nHowever, she also received death-threats due to her work. When talking with her father about it, he said to her “You received a death threat, but you seem happy about it (?)” To that, she said she was because “I at least have done something as a statistician to be kill-worthy.”\n\nOn getting involved with study-design and rollout as a statistician:\nMukherjee argues it’s simply not enough for (bio-)statisticians to wish that the data quality were better, more representative, that it captured marginalized groups with higher coverage, but necessary that (bio-)staticicians get involved and design their own studies in collaboration with epidemiologists and other subject matter experts.\nTo that end, Mukherjee describes her involvement with MyDataHelps, an online mobile-phone centric platform that makes it possible so that participants can contribute their data without having to do long surveys all at once. She emphasized that they can just push one or two questions at a time. On traditional biostatistics, she said that this is why the foundations of our field in sampling design are so crucial: because now, as we adapt what it means to collect data in the 21st century, we have to update our notions of how survey data should be collected and analyzed.\n\n\n\n\n\nLogo for MI-CARES, Understanding the Impact of Our Environment\n\n\n\n\n\n\n\nEnvironmental (in-)justice map\n\n\n\n\nShe also described her involvement in MI-CARES, a huge grant focused on over-sampling racial/ethnic minority populations in Michigan, and to be ‘the one study that does it all’ in terms of capturing cardio-metabolomics, epigenomics, microbiome profiles, mental health, environmental justice, residential measures, discrimination, etc., etc., etc., so that we can truly have one dataset where all of the complexities of health are measured longitudinally (over-time) for a cohort of people who are not traditionally well-represented in science, public health, and medicine.\nShe said of her engagement with fieldwork based science: “That year, if I publish less papers, I don’t care, because I am going to go for glorious failure.” As in, she would rather go for glorious failure attempting to do community-engaged work than traditional success in biostatistics publishing yet another methods paper that only gets cited by subsequent methods papers.\n\nOn Imperfect Data:\nShe referenced Xiaoli Meng’s 2018 article Statistical Paradises and Paradoxes in Big Data: Law of Large Populations, Big Data Paradox, and the 2016 US Presidential Election, which highlighted the “Curse of Large N.”\nShe points out that it doesn’t do much good to shrink the variance of an estimator as \\(N \\to \\infty\\) if the fundamental estimate is biased, because now we are simply becoming “precisely wrong.”\nMukherjee argues that (bio-)statisticians are uniquely poised among the data-analytic disciplines (computer science, mathematics, bioinformatics, data science, machine learning) to address issues like selection bias, aggregation bias, measurement error, survivorship bias, etc., because we are intimately connected with epidemiology and concerned with the data-generating mechanisms that lead to missingness, drop-out, self-selection, loss-to-follow-up, etc., whereas many other disciplines take the data “as given.”\n\n\n\nAn example of the hierarchy of survey-errors, from Response Order Effects in Online Surveys: An Empirical Investigation by Sanjeev M, Int J of Online Marketing\n\n\n\nMy Synthesis:\nIn my opinion, few words can do justice to how inspiring it was to hear from a leader in the field who so unequivocably advocates for the field’s focus on community-engaged work, a social determinants of health -centric vision of health systems, a mission to reverse the vicious cycles of algorithmic bias and discrimination, and who speaks truth to power, asking why tenured faculty are so reluctant to try something new in deviating away from their methodological work to focus on projects with more concrete real-world impact.\nMukherjee was clear: the methodological work has its place, and largely seemed to emphasize that without an early career in methods-focused projects (bringing with them motivation to develop theory underlying the methods), her recent work that is in relation to communities would not have been the same — it would not have been informed by the same methodological considerations, or by her accumulated wealth of knowledge about, say, survey design and methods to account for complex missingness patterns and/or bias-introducing-mechanisms.\nAt once highlighting the merits and shortcomings of the field, Mukherjee leaves us with significant food for thought: it is simply not enough for biostatisticians who aspire to be ‘data dreamers’ to live in an ivory tower focused solely on theoretical considerations when there is so much to contribute to work on-the-ground that reshapes people’s lives for the better. As she reminded me at the event’s reception, for Zelen and Lagakos to present their findings in a church’s basement in Woburn was to truly engage with the public, and to hear someone cry out “Thank God for Marvin Zelen” speaks volumes to the impact our field can have if we center the lived experiences of the communities we want to uplift."
  },
  {
    "objectID": "index.html#about-me",
    "href": "index.html#about-me",
    "title": "Christian Testa",
    "section": "",
    "text": "Hello! I am a first year PhD student in the Department of Biostatistics at the Harvard T.H. Chan School of Public Health. My research interest areas include causal inference, infectious diseases, and spatial statistics.\nRecently I worked (2020-2023) as a statistical data analyst with Nancy Krieger and Jarvis Chen in the Department of Social and Behavioral Sciences at the Harvard T.H. Chan School of Public Health on projects including:\n\nThe Public Health Disparities Geocoding Project 2.0\nTwo NIH R01 grant funded projects:\n\nDNA methylation & adversity: pathways from exposures to health inequities\nAdvancing novel methods to measure and analyze multiple types of discrimination for population health research\n\nA COVID-19 Paper Series"
  },
  {
    "objectID": "posts/2024-09-06-history-of-probability.html",
    "href": "posts/2024-09-06-history-of-probability.html",
    "title": "Brief History of Probability Notes",
    "section": "",
    "text": "Tuesday September 3rd, the first day of our semester, I needed to cover teaching for our professor teaching BST/BIOSTATS 230 Probability I, so as part of that I got to lecture on the history of probability as an academic field, which I thoroughly enjoyed.\nI needed to stick roughly to the gist of his pre-existing slides, but I wanted to give some of my own emphasis to what I presented, so I wrote some lecture notes to go along with the slides.\nPlease find them attached (2024-09-03-notes_for_day_1.pdf).\n\n\n\nScreenshot of lecture notes first page"
  }
]